{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hhab3-O20oX8",
      "metadata": {
        "id": "hhab3-O20oX8"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets accelerate peft bitsandbytes sentencepiece evaluate rouge_score bert-score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZqUvSHUK-3eD",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZqUvSHUK-3eD"
      },
      "outputs": [],
      "source": [
        "# !pip install -qU transformers==4.48.3 datasets==3.2.0 optimum==1.24.0\n",
        "# !pip install -qU openai==1.61.0 wandb\n",
        "!pip install -qU json-repair==0.29.1\n",
        "!pip install -qU faker==35.2.0\n",
        "!pip install -qU vllm==0.7.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Mbqoyz80j9Pd",
      "metadata": {
        "id": "Mbqoyz80j9Pd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "lmJmPhwukFf_",
      "metadata": {
        "id": "lmJmPhwukFf_"
      },
      "source": [
        "## login to huggingface_hub and  wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3lEN8qZYj9S1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lEN8qZYj9S1",
        "outputId": "eec2aca1-63ce-445f-b333-05116e028660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33momaryaser311\u001b[0m (\u001b[33momaryaser311-mansoura-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "from huggingface_hub import login\n",
        "import wandb\n",
        "from google.colab import userdata\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "wandb.login(key=userdata.get('WANDB_API_KEY'))\n",
        "login(token=userdata.get('huggingface_token'), add_to_git_credential=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71u2cMCJkOkQ",
      "metadata": {
        "id": "71u2cMCJkOkQ"
      },
      "source": [
        "## import model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80e6c344",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80e6c344",
        "outputId": "d1585556-7005-45aa-b0b5-31486aca7173"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM , BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "bbc = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_type=torch.float16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    dtype=\"auto\",\n",
        "    quantization_config=bbc,\n",
        "    low_cpu_mem_usage=True,\n",
        ").to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6e1dc7d",
      "metadata": {
        "id": "f6e1dc7d"
      },
      "source": [
        "import needed libriries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36582873",
      "metadata": {
        "id": "36582873"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from os.path import join\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "import requests\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional, Literal\n",
        "from datetime import datetime\n",
        "\n",
        "import json_repair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a76fcb0",
      "metadata": {
        "id": "6a76fcb0"
      },
      "outputs": [],
      "source": [
        "story = \"\"\"\n",
        "ذكرت مجلة فوربس أن العائلة تلعب دورا محوريا في تشكيل علاقة الأفراد بالمال،\n",
        " حيث تتأثر هذه العلاقة بأنماط السلوك المالي المتوارثة عبر الأجيال.\n",
        "\n",
        "التقرير الذي يستند إلى أبحاث الأستاذ الجامعي شاين إنيت حول\n",
        "الرفاه المالي يوضح أن لكل شخص \"شخصية مالية\" تتحدد وفقا لطريقة\n",
        " تفاعله مع المال، والتي تتأثر بشكل مباشر بتربية الأسرة وتجارب الطفولة.\n",
        "\n",
        " الأبعاد الثلاثة للعلاقة بالمال\n",
        "بحسب الدراسة، هناك ثلاثة أبعاد رئيسية تشكّل علاقتنا بالمال:\n",
        "\n",
        "الاكتساب (A): يميل الأفراد الذين ينتمون لهذا\n",
        " البعد إلى اعتبار المال سلعة قابلة للجمع، حيث يرون\n",
        "في تحقيق الثروة هدفا بحد ذاته. والجانب السلبي لهذا\n",
        " النمط هو إمكانية التحول إلى هوس بالثروة أو العكس،\n",
        " أي رفض تام لاكتساب المال باعتباره مصدرا للفساد.\n",
        "\n",
        "الاستخدام (U): يرى هؤلاء الأشخاص المال أداة للتمتع بالحياة، حيث يربطون قيمته بقدرته على توفير\n",
        "المتعة والراحة. ومع ذلك، قد يصبح\n",
        "البعض مدمنا على الإنفاق، في حين يتجه آخرون إلى التقشف المفرط خوفا من المستقبل.\n",
        "\n",
        "الإدارة (M): أصحاب هذا النمط يعتبرون المال مسؤولية تتطلب التخطيط الدقيق. لكن في بعض الحالات،\n",
        " قد يتحول الأمر إلى هوس مفرط بإدارة الإنفاق، مما يؤثر سلبا على العلاقات الشخصية.\n",
        "\n",
        " كيف تؤثر العائلة على علاقتنا بالمال؟\n",
        "يشير التقرير إلى أن التجارب الأسرية تلعب دورا رئيسيا في تحديد\n",
        " \"الشخصية المالية\" لكل فرد، على سبيل المثال، إذا كان أحد الوالدين يعتمد على المال\n",
        "كمكافأة للسلوك الجيد، فقد يتبنى الطفل لاحقا النمط نفسه في حياته البالغة.\n",
        "\n",
        "لتحليل هذه التأثيرات بشكل دقيق، طورت رابطة العلاج المالي\n",
        "(Financial Therapy Association) أداة تسمى مخطط الجينوم المالي (Money Genogram)،\n",
        "وهو نموذج يُستخدم لتحديد الأنماط المالية داخل العائلة.\n",
        "\n",
        "تتضمن هذه الأداة:\n",
        "\n",
        "رسم شجرة عائلية.\n",
        "تصنيف أفراد العائلة وفقا للأبعاد الثلاثة للعلاقة بالمال (A ،U ،M).\n",
        "تحديد ما إذا كان السلوك المالي لكل فرد صحيا (+) أو غير صحي (-).\n",
        "على سبيل المثال، إذا نشأ شخص في عائلة\n",
        "اعتادت على الإنفاق المفرط، فقد يكون لديه ميل قوي إلى اتباع النمط نفسه،\n",
        " أو العكس تماما، حيث يصبح مقتصدا بشكل مبالغ فيه كرد فعل نفسي.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2e009c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2e009c3",
        "outputId": "391ee2f8-3ab7-4cf8-c3ac-b9bea2599962"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-29985894.py:22: PydanticDeprecatedSince20: `min_items` is deprecated and will be removed, use `min_length` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  story_summery : List[str] = Field(... , min_items = 1 , max_items = 5 ,\n",
            "/tmp/ipython-input-29985894.py:22: PydanticDeprecatedSince20: `max_items` is deprecated and will be removed, use `max_length` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  story_summery : List[str] = Field(... , min_items = 1 , max_items = 5 ,\n",
            "/tmp/ipython-input-29985894.py:25: PydanticDeprecatedSince20: `min_items` is deprecated and will be removed, use `min_length` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  story_entites : List[Entity] = Field(..., min_items=1, max_items=10,\n",
            "/tmp/ipython-input-29985894.py:25: PydanticDeprecatedSince20: `max_items` is deprecated and will be removed, use `max_length` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n",
            "  story_entites : List[Entity] = Field(..., min_items=1, max_items=10,\n"
          ]
        }
      ],
      "source": [
        "StoryCategory = Literal[\n",
        "    \"politics\", \"sports\", \"art\", \"technology\", \"economy\",\n",
        "    \"health\", \"entertainment\", \"science\",\n",
        "    \"not_specified\"\n",
        "]\n",
        "\n",
        "EntityType = Literal[\n",
        "    \"person-male\", \"person-female\", \"location\", \"organization\", \"event\", \"time\",\n",
        "    \"quantity\", \"money\", \"product\", \"law\", \"disease\", \"artifact\", \"not_specified\"\n",
        "]\n",
        "\n",
        "class Entity(BaseModel):\n",
        "    entity_value: str = Field(..., description=\"The actual name or value of the entity.\")\n",
        "    entity_type: EntityType = Field(..., description=\"The type of recognized entity.\")\n",
        "\n",
        "\n",
        "class extract_details(BaseModel):\n",
        "    story_title : str = Field(... , min_length=15 , max_length=250 ,\n",
        "                              description=\"a sutiable title for the story\")\n",
        "    story_keywords : List[str]  = Field(... , min_length=20 ,\n",
        "                                        description=\"Relevant keywords associated with the story\")\n",
        "    story_summery : List[str] = Field(... , min_items = 1 , max_items = 5 ,\n",
        "                                      description=\"Summarized key points about the story (1-5 points).\")\n",
        "    story_category : StoryCategory = Field(... , description=\"Category of the news story.\")\n",
        "    story_entites : List[Entity] = Field(..., min_items=1, max_items=10,\n",
        "                                        description=\"List of identified entities in the story.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d2b4f4c",
      "metadata": {
        "id": "1d2b4f4c"
      },
      "source": [
        "Get Format Instrustions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d7cc406",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d7cc406",
        "outputId": "c9051f03-1657-48db-ceb4-3305801cbfa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STRICT OUTPUT FORMAT:\n",
            "- Return only the JSON value that conforms to the schema. Do not include any additional text, explanations, headings, or separators.\n",
            "- Do not wrap the JSON in Markdown or code fences (no ``` or ```json).\n",
            "- Do not prepend or append any text (e.g., do not write \"Here is the JSON:\").\n",
            "- The response must be a single top-level JSON value exactly as required by the schema (object/array/etc.), with no trailing commas or comments.\n",
            "\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]} the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema (shown in a code block for readability only — do not include any backticks or Markdown in your output):\n",
            "```\n",
            "{\"$defs\": {\"Entity\": {\"properties\": {\"entity_value\": {\"description\": \"The actual name or value of the entity.\", \"title\": \"Entity Value\", \"type\": \"string\"}, \"entity_type\": {\"description\": \"The type of recognized entity.\", \"enum\": [\"person-male\", \"person-female\", \"location\", \"organization\", \"event\", \"time\", \"quantity\", \"money\", \"product\", \"law\", \"disease\", \"artifact\", \"not_specified\"], \"title\": \"Entity Type\", \"type\": \"string\"}}, \"required\": [\"entity_value\", \"entity_type\"], \"title\": \"Entity\", \"type\": \"object\"}}, \"properties\": {\"story_title\": {\"description\": \"a sutiable title for the story\", \"maxLength\": 250, \"minLength\": 15, \"title\": \"Story Title\", \"type\": \"string\"}, \"story_keywords\": {\"description\": \"Relevant keywords associated with the story\", \"items\": {\"type\": \"string\"}, \"minItems\": 20, \"title\": \"Story Keywords\", \"type\": \"array\"}, \"story_summery\": {\"description\": \"Summarized key points about the story (1-5 points).\", \"items\": {\"type\": \"string\"}, \"maxItems\": 5, \"minItems\": 1, \"title\": \"Story Summery\", \"type\": \"array\"}, \"story_category\": {\"description\": \"Category of the news story.\", \"enum\": [\"politics\", \"sports\", \"art\", \"technology\", \"economy\", \"health\", \"entertainment\", \"science\", \"not_specified\"], \"title\": \"Story Category\", \"type\": \"string\"}, \"story_entites\": {\"description\": \"List of identified entities in the story.\", \"items\": {\"$ref\": \"#/$defs/Entity\"}, \"maxItems\": 10, \"minItems\": 1, \"title\": \"Story Entites\", \"type\": \"array\"}}, \"required\": [\"story_title\", \"story_keywords\", \"story_summery\", \"story_category\", \"story_entites\"]}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "format_instructions = JsonOutputParser(pydantic_object=extract_details).get_format_instructions()\n",
        "print(format_instructions)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f58ba10d",
      "metadata": {
        "id": "f58ba10d"
      },
      "source": [
        "Built The details_extraction_messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bb3063d",
      "metadata": {
        "id": "9bb3063d"
      },
      "outputs": [],
      "source": [
        "details_extraction_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\\n\".join([\n",
        "            \"You are an NLP data paraser.\",\n",
        "            \"You will be provided by an Arabic text associated with a Pydantic scheme.\",\n",
        "            \"Generate the ouptut in the same story language.\",\n",
        "            \"You have to extract JSON details from text according the Pydantic details.\",\n",
        "            \"Extract details as mentioned in text.\",\n",
        "            \"Do not generate any introduction or conclusion.\"\n",
        "        ])\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\\n\".join([\n",
        "            \"## Story:\",\n",
        "            story.strip(),\n",
        "            \"\",\n",
        "\n",
        "            \"## Pydantic Details:\",\n",
        "            format_instructions ,\n",
        "            \"\",\n",
        "\n",
        "            \"## Story Details:\",\n",
        "            \"```json\"\n",
        "        ])\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SitCybwf3KhC",
      "metadata": {
        "id": "SitCybwf3KhC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c6aea64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c6aea64",
        "outputId": "98cbe60d-5fad-403c-d525-2dca4670993c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': 'You are an NLP data paraser.\\nYou will be provided by an Arabic text associated with a Pydantic scheme.\\nGenerate the ouptut in the same story language.\\nYou have to extract JSON details from text according the Pydantic details.\\nExtract details as mentioned in text.\\nDo not generate any introduction or conclusion.'},\n",
              " {'role': 'user',\n",
              "  'content': '## Story:\\nذكرت مجلة فوربس أن العائلة تلعب دورا محوريا في تشكيل علاقة الأفراد بالمال،\\n حيث تتأثر هذه العلاقة بأنماط السلوك المالي المتوارثة عبر الأجيال.\\n\\nالتقرير الذي يستند إلى أبحاث الأستاذ الجامعي شاين إنيت حول\\nالرفاه المالي يوضح أن لكل شخص \"شخصية مالية\" تتحدد وفقا لطريقة\\n تفاعله مع المال، والتي تتأثر بشكل مباشر بتربية الأسرة وتجارب الطفولة.\\n\\n الأبعاد الثلاثة للعلاقة بالمال\\nبحسب الدراسة، هناك ثلاثة أبعاد رئيسية تشكّل علاقتنا بالمال:\\n\\nالاكتساب (A): يميل الأفراد الذين ينتمون لهذا\\n البعد إلى اعتبار المال سلعة قابلة للجمع، حيث يرون\\nفي تحقيق الثروة هدفا بحد ذاته. والجانب السلبي لهذا\\n النمط هو إمكانية التحول إلى هوس بالثروة أو العكس،\\n أي رفض تام لاكتساب المال باعتباره مصدرا للفساد.\\n\\nالاستخدام (U): يرى هؤلاء الأشخاص المال أداة للتمتع بالحياة، حيث يربطون قيمته بقدرته على توفير\\nالمتعة والراحة. ومع ذلك، قد يصبح\\nالبعض مدمنا على الإنفاق، في حين يتجه آخرون إلى التقشف المفرط خوفا من المستقبل.\\n\\nالإدارة (M): أصحاب هذا النمط يعتبرون المال مسؤولية تتطلب التخطيط الدقيق. لكن في بعض الحالات،\\n قد يتحول الأمر إلى هوس مفرط بإدارة الإنفاق، مما يؤثر سلبا على العلاقات الشخصية.\\n\\n كيف تؤثر العائلة على علاقتنا بالمال؟\\nيشير التقرير إلى أن التجارب الأسرية تلعب دورا رئيسيا في تحديد\\n \"الشخصية المالية\" لكل فرد، على سبيل المثال، إذا كان أحد الوالدين يعتمد على المال\\nكمكافأة للسلوك الجيد، فقد يتبنى الطفل لاحقا النمط نفسه في حياته البالغة.\\n\\nلتحليل هذه التأثيرات بشكل دقيق، طورت رابطة العلاج المالي\\n(Financial Therapy Association) أداة تسمى مخطط الجينوم المالي (Money Genogram)،\\nوهو نموذج يُستخدم لتحديد الأنماط المالية داخل العائلة.\\n\\nتتضمن هذه الأداة:\\n\\nرسم شجرة عائلية.\\nتصنيف أفراد العائلة وفقا للأبعاد الثلاثة للعلاقة بالمال (A ،U ،M).\\nتحديد ما إذا كان السلوك المالي لكل فرد صحيا (+) أو غير صحي (-).\\nعلى سبيل المثال، إذا نشأ شخص في عائلة\\nاعتادت على الإنفاق المفرط، فقد يكون لديه ميل قوي إلى اتباع النمط نفسه،\\n أو العكس تماما، حيث يصبح مقتصدا بشكل مبالغ فيه كرد فعل نفسي.\\n\\n## Pydantic Details:\\nSTRICT OUTPUT FORMAT:\\n- Return only the JSON value that conforms to the schema. Do not include any additional text, explanations, headings, or separators.\\n- Do not wrap the JSON in Markdown or code fences (no ``` or ```json).\\n- Do not prepend or append any text (e.g., do not write \"Here is the JSON:\").\\n- The response must be a single top-level JSON value exactly as required by the schema (object/array/etc.), with no trailing commas or comments.\\n\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]} the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema (shown in a code block for readability only — do not include any backticks or Markdown in your output):\\n```\\n{\"$defs\": {\"Entity\": {\"properties\": {\"entity_value\": {\"description\": \"The actual name or value of the entity.\", \"title\": \"Entity Value\", \"type\": \"string\"}, \"entity_type\": {\"description\": \"The type of recognized entity.\", \"enum\": [\"person-male\", \"person-female\", \"location\", \"organization\", \"event\", \"time\", \"quantity\", \"money\", \"product\", \"law\", \"disease\", \"artifact\", \"not_specified\"], \"title\": \"Entity Type\", \"type\": \"string\"}}, \"required\": [\"entity_value\", \"entity_type\"], \"title\": \"Entity\", \"type\": \"object\"}}, \"properties\": {\"story_title\": {\"description\": \"a sutiable title for the story\", \"maxLength\": 250, \"minLength\": 15, \"title\": \"Story Title\", \"type\": \"string\"}, \"story_keywords\": {\"description\": \"Relevant keywords associated with the story\", \"items\": {\"type\": \"string\"}, \"minItems\": 20, \"title\": \"Story Keywords\", \"type\": \"array\"}, \"story_summery\": {\"description\": \"Summarized key points about the story (1-5 points).\", \"items\": {\"type\": \"string\"}, \"maxItems\": 5, \"minItems\": 1, \"title\": \"Story Summery\", \"type\": \"array\"}, \"story_category\": {\"description\": \"Category of the news story.\", \"enum\": [\"politics\", \"sports\", \"art\", \"technology\", \"economy\", \"health\", \"entertainment\", \"science\", \"not_specified\"], \"title\": \"Story Category\", \"type\": \"string\"}, \"story_entites\": {\"description\": \"List of identified entities in the story.\", \"items\": {\"$ref\": \"#/$defs/Entity\"}, \"maxItems\": 10, \"minItems\": 1, \"title\": \"Story Entites\", \"type\": \"array\"}}, \"required\": [\"story_title\", \"story_keywords\", \"story_summery\", \"story_category\", \"story_entites\"]}\\n```\\n\\n## Story Details:\\n```json'}]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "details_extraction_messages"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e64ee69",
      "metadata": {
        "id": "9e64ee69"
      },
      "source": [
        "Every Model has It's Own chat_template Before tokinze the details_extraction_messages we sirst should apply_chat_template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e4501f3",
      "metadata": {
        "id": "4e4501f3"
      },
      "outputs": [],
      "source": [
        "text = tokenizer.apply_chat_template(\n",
        "    details_extraction_messages,#\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d603911",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "8d603911",
        "outputId": "783620d8-821e-44a1-cd0c-3e4d4bcebd65"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<|im_start|>system\\nYou are an NLP data paraser.\\nYou will be provided by an Arabic text associated with a Pydantic scheme.\\nGenerate the ouptut in the same story language.\\nYou have to extract JSON details from text according the Pydantic details.\\nExtract details as mentioned in text.\\nDo not generate any introduction or conclusion.<|im_end|>\\n<|im_start|>user\\n## Story:\\nذكرت مجلة فوربس أن العائلة تلعب دورا محوريا في تشكيل علاقة الأفراد بالمال،\\n حيث تتأثر هذه العلاقة بأنماط السلوك المالي المتوارثة عبر الأجيال.\\n\\nالتقرير الذي يستند إلى أبحاث الأستاذ الجامعي شاين إنيت حول\\nالرفاه المالي يوضح أن لكل شخص \"شخصية مالية\" تتحدد وفقا لطريقة\\n تفاعله مع المال، والتي تتأثر بشكل مباشر بتربية الأسرة وتجارب الطفولة.\\n\\n الأبعاد الثلاثة للعلاقة بالمال\\nبحسب الدراسة، هناك ثلاثة أبعاد رئيسية تشكّل علاقتنا بالمال:\\n\\nالاكتساب (A): يميل الأفراد الذين ينتمون لهذا\\n البعد إلى اعتبار المال سلعة قابلة للجمع، حيث يرون\\nفي تحقيق الثروة هدفا بحد ذاته. والجانب السلبي لهذا\\n النمط هو إمكانية التحول إلى هوس بالثروة أو العكس،\\n أي رفض تام لاكتساب المال باعتباره مصدرا للفساد.\\n\\nالاستخدام (U): يرى هؤلاء الأشخاص المال أداة للتمتع بالحياة، حيث يربطون قيمته بقدرته على توفير\\nالمتعة والراحة. ومع ذلك، قد يصبح\\nالبعض مدمنا على الإنفاق، في حين يتجه آخرون إلى التقشف المفرط خوفا من المستقبل.\\n\\nالإدارة (M): أصحاب هذا النمط يعتبرون المال مسؤولية تتطلب التخطيط الدقيق. لكن في بعض الحالات،\\n قد يتحول الأمر إلى هوس مفرط بإدارة الإنفاق، مما يؤثر سلبا على العلاقات الشخصية.\\n\\n كيف تؤثر العائلة على علاقتنا بالمال؟\\nيشير التقرير إلى أن التجارب الأسرية تلعب دورا رئيسيا في تحديد\\n \"الشخصية المالية\" لكل فرد، على سبيل المثال، إذا كان أحد الوالدين يعتمد على المال\\nكمكافأة للسلوك الجيد، فقد يتبنى الطفل لاحقا النمط نفسه في حياته البالغة.\\n\\nلتحليل هذه التأثيرات بشكل دقيق، طورت رابطة العلاج المالي\\n(Financial Therapy Association) أداة تسمى مخطط الجينوم المالي (Money Genogram)،\\nوهو نموذج يُستخدم لتحديد الأنماط المالية داخل العائلة.\\n\\nتتضمن هذه الأداة:\\n\\nرسم شجرة عائلية.\\nتصنيف أفراد العائلة وفقا للأبعاد الثلاثة للعلاقة بالمال (A ،U ،M).\\nتحديد ما إذا كان السلوك المالي لكل فرد صحيا (+) أو غير صحي (-).\\nعلى سبيل المثال، إذا نشأ شخص في عائلة\\nاعتادت على الإنفاق المفرط، فقد يكون لديه ميل قوي إلى اتباع النمط نفسه،\\n أو العكس تماما، حيث يصبح مقتصدا بشكل مبالغ فيه كرد فعل نفسي.\\n\\n## Pydantic Details:\\nSTRICT OUTPUT FORMAT:\\n- Return only the JSON value that conforms to the schema. Do not include any additional text, explanations, headings, or separators.\\n- Do not wrap the JSON in Markdown or code fences (no ``` or ```json).\\n- Do not prepend or append any text (e.g., do not write \"Here is the JSON:\").\\n- The response must be a single top-level JSON value exactly as required by the schema (object/array/etc.), with no trailing commas or comments.\\n\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]} the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema (shown in a code block for readability only — do not include any backticks or Markdown in your output):\\n```\\n{\"$defs\": {\"Entity\": {\"properties\": {\"entity_value\": {\"description\": \"The actual name or value of the entity.\", \"title\": \"Entity Value\", \"type\": \"string\"}, \"entity_type\": {\"description\": \"The type of recognized entity.\", \"enum\": [\"person-male\", \"person-female\", \"location\", \"organization\", \"event\", \"time\", \"quantity\", \"money\", \"product\", \"law\", \"disease\", \"artifact\", \"not_specified\"], \"title\": \"Entity Type\", \"type\": \"string\"}}, \"required\": [\"entity_value\", \"entity_type\"], \"title\": \"Entity\", \"type\": \"object\"}}, \"properties\": {\"story_title\": {\"description\": \"a sutiable ttitle for the story\", \"maxLength\": 250, \"minLength\": 15, \"title\": \"Story Title\", \"type\": \"string\"}, \"story_keywords\": {\"description\": \"Relevant keywords associated with the story\", \"items\": {\"type\": \"string\"}, \"minItems\": 20, \"title\": \"Story Keywords\", \"type\": \"array\"}, \"story_summery\": {\"description\": \"Summarized key points about the story (1-5 points).\", \"items\": {\"type\": \"string\"}, \"maxItems\": 5, \"minItems\": 1, \"title\": \"Story Summery\", \"type\": \"array\"}, \"story_category\": {\"description\": \"Category of the news story.\", \"enum\": [\"politics\", \"sports\", \"art\", \"technology\", \"economy\", \"health\", \"entertainment\", \"science\", \"not_specified\"], \"title\": \"Story Category\", \"type\": \"string\"}, \"story_entites\": {\"description\": \"List of identified entities in the story.\", \"items\": {\"$ref\": \"#/$defs/Entity\"}, \"maxItems\": 10, \"minItems\": 1, \"title\": \"Story Entites\", \"type\": \"array\"}}, \"required\": [\"story_title\", \"story_keywords\", \"story_summery\", \"story_category\", \"story_entites\"]}\\n```\\n\\n## Story Details:\\n```json<|im_end|>\\n<|im_start|>assistant\\n'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40b537f4",
      "metadata": {
        "id": "40b537f4"
      },
      "source": [
        "Tokinize Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39ecbc35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39ecbc35",
        "outputId": "9126462b-7f52-4d20-f5e4-0aea5889a9ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        }
      ],
      "source": [
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    model_inputs.input_ids,\n",
        "    max_new_tokens=1024,\n",
        "    do_sample=False, top_k=None, temperature=None, top_p=None,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11b975fa",
      "metadata": {
        "id": "11b975fa"
      },
      "source": [
        "Return Outpot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2125dd9",
      "metadata": {
        "id": "a2125dd9"
      },
      "outputs": [],
      "source": [
        "generated_ids = [\n",
        "    output_ids[len(input_ids):] # بما ان بيرجع الانبوت مع الاوبتوبت فان اعاوز ابدا بالاوبوت بس اعرضه ف ببدا من نهايه الانبوت لان بعدها هيتكتب الابتوبت\n",
        "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "] #generated_ids بيرجع الانبوت مع الاوبتبوت يعني البرومبت مع الناتج ليه او الرد بس علي شكل ايديهات علشان كده استخدمنا model_inputs.input_ids\n",
        "\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0] # skip_special_tokens=True دا لان المودل بسبب التشات تمبليت بيضيف توكنز خاص بيه زي ايم استرت واسسيسمنت وهكذا فانا مش عاوزها"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a67a6e03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a67a6e03",
        "outputId": "914425e9-b54c-47cd-fc09-1180f4b4f094"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "{\n",
            "  \"story_title\": \"The Role of Family in Financial Relationships\",\n",
            "  \"story_keywords\": [\n",
            "    \"family influence on money\",\n",
            "    \"financial relationships\",\n",
            "    \"inheritance patterns\",\n",
            "    \"personal finance\",\n",
            "    \"economic impact\",\n",
            "    \"parental influence\",\n",
            "    \"child development\",\n",
            "    \"wealth management\",\n",
            "    \"social dynamics\"\n",
            "  ],\n",
            "  \"story_summery\": [\n",
            "    \"Families play a crucial role in shaping individual financial behaviors and attitudes.\",\n",
            "    \"Inherited financial habits can significantly affect how individuals approach wealth and money throughout their lives.\",\n",
            "    \"Understanding these inherited traits helps in developing effective strategies for managing personal finances.\"\n",
            "  ],\n",
            "  \"story_category\": \"economy\",\n",
            "  \"story_entites\": [\n",
            "    {\n",
            "      \"entity_value\": \"Financial Therapy Association\",\n",
            "      \"entity_type\": \"organization\"\n",
            "    },\n",
            "    {\n",
            "      \"entity_value\": \"Shawn Ennett\",\n",
            "      \"entity_type\": \"person\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "# we wanted the details to be in the same lang of the story we told the model that but it answer with diffrent lang\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0824b0c",
      "metadata": {
        "id": "b0824b0c"
      },
      "source": [
        "Task 2 : Translation Of Story"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18f5731b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18f5731b",
        "outputId": "1f063a88-bcd7-4927-9d97-c8e66b67a998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "STRICT OUTPUT FORMAT:\n",
            "- Return only the JSON value that conforms to the schema. Do not include any additional text, explanations, headings, or separators.\n",
            "- Do not wrap the JSON in Markdown or code fences (no ``` or ```json).\n",
            "- Do not prepend or append any text (e.g., do not write \"Here is the JSON:\").\n",
            "- The response must be a single top-level JSON value exactly as required by the schema (object/array/etc.), with no trailing commas or comments.\n",
            "\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]} the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema (shown in a code block for readability only — do not include any backticks or Markdown in your output):\n",
            "```\n",
            "{\"properties\": {\"translated_title\": {\"description\": \"Suggested translated title of the news story.\", \"maxLength\": 300, \"minLength\": 5, \"title\": \"Translated Title\", \"type\": \"string\"}, \"translated_content\": {\"description\": \"Translated content of the news story.\", \"minLength\": 5, \"title\": \"Translated Content\", \"type\": \"string\"}}, \"required\": [\"translated_title\", \"translated_content\"]}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "class TranslatedStory(BaseModel):\n",
        "    translated_title: str = Field(..., min_length=5, max_length=300,\n",
        "                                  description=\"Suggested translated title of the news story.\")\n",
        "    translated_content: str = Field(..., min_length=5,\n",
        "                                    description=\"Translated content of the news story.\")\n",
        "\n",
        "#  format_instructions of TranslatedStory\n",
        "format_instructions_for_TranslatedStory = JsonOutputParser(pydantic_object=TranslatedStory).get_format_instructions()\n",
        "print(format_instructions_for_TranslatedStory)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8896c14",
      "metadata": {
        "id": "b8896c14"
      },
      "source": [
        "Built Translation Message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82f348bb",
      "metadata": {
        "id": "82f348bb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c782ccb5",
      "metadata": {
        "id": "c782ccb5"
      },
      "outputs": [],
      "source": [
        "Targeted_Language = \"French\"\n",
        "translation_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\\n\".join([\n",
        "            \"You are a professional translator.\",\n",
        "            \"You will be provided by an Arabic text.\",\n",
        "            \"You have to translate the text into the `Targeted Language`.\",\n",
        "            \"Follow the provided Scheme to generate a JSON\",\n",
        "            \"Do not generate any introduction or conclusion.\"\n",
        "        ])\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\\n\".join([\n",
        "            \"## Story:\",\n",
        "            story.strip(),\n",
        "            \"\",\n",
        "            \"## Targeted Language\" ,\n",
        "            Targeted_Language ,\n",
        "            \"\",\n",
        "\n",
        "            \"## Pydantic Details:\",\n",
        "            format_instructions_for_TranslatedStory ,\n",
        "            \"\",\n",
        "\n",
        "            \"## Story Details:\",\n",
        "            \"```json\"\n",
        "        ])\n",
        "    }]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c742a44",
      "metadata": {
        "id": "2c742a44"
      },
      "source": [
        "apply_chat_template on  translation_messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55cba6cb",
      "metadata": {
        "id": "55cba6cb"
      },
      "outputs": [],
      "source": [
        "text = tokenizer.apply_chat_template(\n",
        "    translation_messages ,\n",
        "    tokenize=False, # telling the llm not to tokinze it to numbers now\n",
        "    add_generation_prompt=True # adds <|im_start|>assistant at the end to notice the model to satrt answer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58740a00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58740a00",
        "outputId": "997a8136-91c3-49a4-b9ff-ace674bcbcb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<|im_start|>system\n",
            "You are a professional translator.\n",
            "You will be provided by an Arabic text.\n",
            "You have to translate the text into the `Targeted Language`.\n",
            "Follow the provided Scheme to generate a JSON\n",
            "Do not generate any introduction or conclusion.<|im_end|>\n",
            "<|im_start|>user\n",
            "## Story:\n",
            "ذكرت مجلة فوربس أن العائلة تلعب دورا محوريا في تشكيل علاقة الأفراد بالمال،\n",
            " حيث تتأثر هذه العلاقة بأنماط السلوك المالي المتوارثة عبر الأجيال.\n",
            "\n",
            "التقرير الذي يستند إلى أبحاث الأستاذ الجامعي شاين إنيت حول\n",
            "الرفاه المالي يوضح أن لكل شخص \"شخصية مالية\" تتحدد وفقا لطريقة\n",
            " تفاعله مع المال، والتي تتأثر بشكل مباشر بتربية الأسرة وتجارب الطفولة.\n",
            "\n",
            " الأبعاد الثلاثة للعلاقة بالمال\n",
            "بحسب الدراسة، هناك ثلاثة أبعاد رئيسية تشكّل علاقتنا بالمال:\n",
            "\n",
            "الاكتساب (A): يميل الأفراد الذين ينتمون لهذا\n",
            " البعد إلى اعتبار المال سلعة قابلة للجمع، حيث يرون\n",
            "في تحقيق الثروة هدفا بحد ذاته. والجانب السلبي لهذا\n",
            " النمط هو إمكانية التحول إلى هوس بالثروة أو العكس،\n",
            " أي رفض تام لاكتساب المال باعتباره مصدرا للفساد.\n",
            "\n",
            "الاستخدام (U): يرى هؤلاء الأشخاص المال أداة للتمتع بالحياة، حيث يربطون قيمته بقدرته على توفير\n",
            "المتعة والراحة. ومع ذلك، قد يصبح\n",
            "البعض مدمنا على الإنفاق، في حين يتجه آخرون إلى التقشف المفرط خوفا من المستقبل.\n",
            "\n",
            "الإدارة (M): أصحاب هذا النمط يعتبرون المال مسؤولية تتطلب التخطيط الدقيق. لكن في بعض الحالات،\n",
            " قد يتحول الأمر إلى هوس مفرط بإدارة الإنفاق، مما يؤثر سلبا على العلاقات الشخصية.\n",
            "\n",
            " كيف تؤثر العائلة على علاقتنا بالمال؟\n",
            "يشير التقرير إلى أن التجارب الأسرية تلعب دورا رئيسيا في تحديد\n",
            " \"الشخصية المالية\" لكل فرد، على سبيل المثال، إذا كان أحد الوالدين يعتمد على المال\n",
            "كمكافأة للسلوك الجيد، فقد يتبنى الطفل لاحقا النمط نفسه في حياته البالغة.\n",
            "\n",
            "لتحليل هذه التأثيرات بشكل دقيق، طورت رابطة العلاج المالي\n",
            "(Financial Therapy Association) أداة تسمى مخطط الجينوم المالي (Money Genogram)،\n",
            "وهو نموذج يُستخدم لتحديد الأنماط المالية داخل العائلة.\n",
            "\n",
            "تتضمن هذه الأداة:\n",
            "\n",
            "رسم شجرة عائلية.\n",
            "تصنيف أفراد العائلة وفقا للأبعاد الثلاثة للعلاقة بالمال (A ،U ،M).\n",
            "تحديد ما إذا كان السلوك المالي لكل فرد صحيا (+) أو غير صحي (-).\n",
            "على سبيل المثال، إذا نشأ شخص في عائلة\n",
            "اعتادت على الإنفاق المفرط، فقد يكون لديه ميل قوي إلى اتباع النمط نفسه،\n",
            " أو العكس تماما، حيث يصبح مقتصدا بشكل مبالغ فيه كرد فعل نفسي.\n",
            "\n",
            "## Targeted Language\n",
            "French\n",
            "\n",
            "## Pydantic Details:\n",
            "STRICT OUTPUT FORMAT:\n",
            "- Return only the JSON value that conforms to the schema. Do not include any additional text, explanations, headings, or separators.\n",
            "- Do not wrap the JSON in Markdown or code fences (no ``` or ```json).\n",
            "- Do not prepend or append any text (e.g., do not write \"Here is the JSON:\").\n",
            "- The response must be a single top-level JSON value exactly as required by the schema (object/array/etc.), with no trailing commas or comments.\n",
            "\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]} the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema (shown in a code block for readability only — do not include any backticks or Markdown in your output):\n",
            "```\n",
            "{\"properties\": {\"translated_title\": {\"description\": \"Suggested translated title of the news story.\", \"maxLength\": 300, \"minLength\": 5, \"title\": \"Translated Title\", \"type\": \"string\"}, \"translated_content\": {\"description\": \"Translated content of the news story.\", \"minLength\": 5, \"title\": \"Translated Content\", \"type\": \"string\"}}, \"required\": [\"translated_title\", \"translated_content\"]}\n",
            "```\n",
            "\n",
            "## Story Details:\n",
            "```json<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60270fab",
      "metadata": {
        "id": "60270fab"
      },
      "source": [
        "tokinze text & Generate Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0c3e4d9",
      "metadata": {
        "id": "d0c3e4d9"
      },
      "outputs": [],
      "source": [
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    model_inputs.input_ids,\n",
        "    max_new_tokens=1024,\n",
        "    do_sample=False, top_k=None, temperature=None, top_p=None,\n",
        ")\n",
        "# response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0] /"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c10e29a",
      "metadata": {
        "id": "9c10e29a"
      },
      "outputs": [],
      "source": [
        "generated_ids = [\n",
        "    output_ids[len(input_ids):] # بما ان بيرجع الانبوت مع الاوبتوبت فان اعاوز ابدا بالاوبوت بس اعرضه ف ببدا من نهايه الانبوت لان بعدها هيتكتب الابتوبت\n",
        "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "] #generated_ids بيرجع الانبوت مع الاوبتبوت يعني البرومبت مع الناتج ليه او الرد بس علي شكل ايديهات علشان كده استخدمنا model_inputs.input_ids\n",
        "\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c567ca4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c567ca4c",
        "outputId": "c14ee951-f8cf-42d4-96fe-c4e39d2b55b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "{\n",
            "  \"translated_title\": \"La famille joue un rôle crucial dans la formation des relations financières\",\n",
            "  \"translated_content\": \"Une étude de l'Université de Stanford a montré que chaque individu possède une «personnalité financière» déterminée par sa façon d'échanger avec les fonds, qui est influencée directement par le mode de vie et la culture familiale.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2ea1937",
      "metadata": {
        "id": "f2ea1937"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1ed37f72",
      "metadata": {
        "id": "1ed37f72"
      },
      "source": [
        "Evaluate LLama3.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cb72ed0",
      "metadata": {
        "id": "2cb72ed0"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c85cee83",
      "metadata": {
        "id": "c85cee83"
      },
      "source": [
        "## Using Chat Model + LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76c6ee98",
      "metadata": {
        "id": "76c6ee98"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "llm = ChatOllama(model=\"llama3.1:latest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a75d555f",
      "metadata": {
        "id": "a75d555f"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "\n",
        "\n",
        "format_instructions = JsonOutputParser(pydantic_object=extract_details).get_format_instructions()\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are an NLP data parser.\n",
        "You will be provided with an Arabic story and a Pydantic schema.\n",
        "Generate the output in the same language as the story.\n",
        "Extract JSON details from the story according to the schema.\n",
        "Only extract what is mentioned explicitly.\n",
        "Do not generate any introduction or conclusion.\n",
        "\n",
        "## Story:\n",
        "{story.strip()}\n",
        "\n",
        "## Pydantic Details:\n",
        "{format_instructions}\n",
        "\n",
        "## Story Details:\n",
        "```json\n",
        "\"\"\"\n",
        "\n",
        "response = llm.invoke(prompt)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c4d881c",
      "metadata": {
        "id": "5c4d881c"
      },
      "source": [
        "llama3 gives us the result that we want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f3f70e0",
      "metadata": {
        "id": "3f3f70e0"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "templete = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", '''You are an NLP data parser. \\\n",
        "    You will be provided with an Arabic story and a Pydantic schema. \\\n",
        "    Generate the output in the same language as the story. \\\n",
        "    Extract JSON details from the story according to the schema. \\\n",
        "    Only extract what is mentioned explicitly. \\\n",
        "    Do not generate any introduction or conclusion.'''),\n",
        "\n",
        "    (\"human\", '''## Story:\n",
        "    {story}\n",
        "\n",
        "    ## Pydantic Details:\n",
        "    {format_instructions}\n",
        "\n",
        "    ## Story Details:\n",
        "    ```json\n",
        "    ''')\n",
        "])\n",
        "\n",
        "\n",
        "chain = templete | llm | JsonOutputParser(pydantic_object=extract_details)\n",
        "response = chain.invoke({\n",
        "    \"story\" :story.strip(),\n",
        "    \"format_instructions\" : format_instructions\n",
        "})\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80bb1f8f",
      "metadata": {
        "id": "80bb1f8f"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77342ca6",
      "metadata": {
        "id": "77342ca6"
      },
      "outputs": [],
      "source": [
        "# llama 3 on Translation Task\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "templete = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", '''You are a professional translator. \\\n",
        "    You will be provided by an Arabic text. \\\n",
        "    You have to translate the text into the `Targeted Language`. \\\n",
        "    Follow the provided Scheme to generate a JSON. \\\n",
        "    Do not generate any introduction or conclusion.'''),\n",
        "\n",
        "    (\"human\", '''## Story:\n",
        "    {story}\n",
        "    ## Targeted Language:\n",
        "    {Targeted_Language}\n",
        "\n",
        "    ## Pydantic Details:\n",
        "    {format_instructions}\n",
        "\n",
        "    ## Story Details:\n",
        "    ```json\n",
        "    ''')\n",
        "])\n",
        "\n",
        "\n",
        "chain = templete | llm | JsonOutputParser(pydantic_object=extract_details)\n",
        "response = chain.invoke({\n",
        "    \"story\" :story.strip(),\n",
        "    \"Targeted_Language\" : \"English\" ,\n",
        "    \"format_instructions\" : format_instructions_for_TranslatedStory\n",
        "})\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e116a8fc",
      "metadata": {
        "id": "e116a8fc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e261511c",
      "metadata": {
        "id": "e261511c"
      },
      "source": [
        "## Knowledge Distillation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7840b538",
      "metadata": {
        "id": "7840b538"
      },
      "source": [
        "Load Stories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac571a3f",
      "metadata": {
        "id": "ac571a3f"
      },
      "outputs": [],
      "source": [
        "# import rand.\n",
        "data = []\n",
        "with open('./Stories/news-sample.jsonl', 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        if line.strip():  # تجاهل الأسطر الفارغة\n",
        "            data.append(json.loads(line))\n",
        "\n",
        "random.Random(101).shuffle(data) # do shuffle because sometimes data are arranged like all sports then all politics and so on\n",
        "\n",
        "print(f\"Loaded {len(data)} records.\")\n",
        "print(data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9b77a24",
      "metadata": {
        "id": "d9b77a24"
      },
      "outputs": [],
      "source": [
        "print(data[0]['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b71aeeb",
      "metadata": {
        "id": "9b71aeeb"
      },
      "outputs": [],
      "source": [
        "save_to = join(\"Stories\", \"sft.jsonl\")\n",
        "\n",
        "for story in tqdm(data) :\n",
        "    templete = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", '''You are an NLP data parser. \\\n",
        "    You will be provided with an Arabic story and a Pydantic schema. \\\n",
        "    Generate the output in the same language as the story. \\\n",
        "    Extract JSON details from the story according to the schema. \\\n",
        "    Only extract what is mentioned explicitly. \\\n",
        "    Do not generate any introduction or conclusion.'''),\n",
        "\n",
        "    (\"human\", '''## Story:\n",
        "    {story}\n",
        "\n",
        "    ## Pydantic Details:\n",
        "    {format_instructions}\n",
        "\n",
        "    ## Story Details:\n",
        "    ```json\n",
        "    ''')\n",
        "    ])\n",
        "\n",
        "    chain = templete | llm | JsonOutputParser(pydantic_object=extract_details)\n",
        "    response = chain.invoke({\n",
        "        \"story\" :story.strip(),\n",
        "        \"format_instructions\" : format_instructions\n",
        "    })\n",
        "\n",
        "    with open(save_to , 'a' ,encoding=\"utf-8\") as saved_json :\n",
        "        saved_json.write(json.dumps({\n",
        "            \"story\": story['content'].strip(),\n",
        "            \"task\": \"Extrat the story details into a JSON.\",\n",
        "            \"output_scheme\": format_instructions,\n",
        "            \"response\": response,\n",
        "        }, ensure_ascii=False, default=str)  + \"\\n\" )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee0fb589",
      "metadata": {
        "id": "ee0fb589"
      },
      "outputs": [],
      "source": [
        "# For Translation\n",
        "\n",
        "save_to = join(\"Stories\", \"sft.jsonl\")\n",
        "\n",
        "for story in tqdm(data) :\n",
        "    templete = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", '''You are a professional translator. \\\n",
        "        You will be provided by an Arabic text. \\\n",
        "        You have to translate the text into the `Targeted Language`. \\\n",
        "        Follow the provided Scheme to generate a JSON. \\\n",
        "        Do not generate any introduction or conclusion.'''),\n",
        "\n",
        "        (\"human\", '''## Story:\n",
        "    {story}\n",
        "    ## Targeted Language:\n",
        "    {Targeted_Language}\n",
        "\n",
        "    ## Pydantic Details:\n",
        "    {format_instructions}\n",
        "\n",
        "    ## Story Details:\n",
        "    ```json\n",
        "    ''')\n",
        "    ])\n",
        "\n",
        "    chain = templete | llm | JsonOutputParser(pydantic_object=TranslatedStory)\n",
        "    response = chain.invoke({\n",
        "        \"story\" :story.strip(),\n",
        "        \"Targeted_Language\" : \"English\" ,\n",
        "        \"format_instructions\" : format_instructions_for_TranslatedStory\n",
        "    })\n",
        "\n",
        "\n",
        "    with open(save_to , 'a' ,encoding=\"utf-8\") as saved_json :\n",
        "        saved_json.write(json.dumps({\n",
        "            \"story\": story['content'].strip(),\n",
        "            \"task\": \"Translate the story Content into another Langauge.\",\n",
        "            \"output_scheme\": format_instructions_for_TranslatedStory,\n",
        "            \"response\": response,\n",
        "        }, ensure_ascii=False, default=str)  + \"\\n\" )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c2f05e6",
      "metadata": {
        "id": "6c2f05e6"
      },
      "source": [
        "## Format Finetuning Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VHV_IssJ1YNy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHV_IssJ1YNy",
        "outputId": "415f3292-51e5-4912-8c7b-6e8224a90471"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/MyDrive/fine_tunning_qwenn/train_ds/train.rar\n",
            "\n",
            "Creating    /content/data                                             OK\n",
            "Extracting  /content/data/train.json                                     \b\b\b\b 75%\b\b\b\b100%\b\b\b\b\b  OK \n",
            "All OK\n",
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/drive/MyDrive/fine_tunning_qwenn/val_ds/val.rar\n",
            "\n",
            "Extracting  /content/data/val.json                                       \b\b\b\b100%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!unrar x \"/content/drive/MyDrive/fine_tunning_qwenn/train_ds/train.rar\" \"/content/data/\"\n",
        "!unrar x \"/content/drive/MyDrive/fine_tunning_qwenn/val_ds/val.rar\" \"/content/data/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd2f7b96",
      "metadata": {
        "id": "dd2f7b96"
      },
      "outputs": [],
      "source": [
        "\n",
        "sft_data_path = join(\"./Stories\", \"sft.jsonl\")\n",
        "llm_finetunning_data = []\n",
        "\n",
        "system_message = \"\\n\".join([\n",
        "    \"You are a professional NLP data parser.\",\n",
        "    \"Follow the provided `Task` by the user and the `Output Scheme` to generate the `Output JSON`.\",\n",
        "    \"Do not generate any introduction or conclusion.\"\n",
        "])\n",
        "\n",
        "for line in open(sft_data_path , encoding='utf-8'):\n",
        "    if line.strip() == \"\":\n",
        "        continue\n",
        "\n",
        "    rec = json.loads(line.strip())\n",
        "\n",
        "    llm_finetunning_data.append({\n",
        "        \"system\": system_message,\n",
        "        \"instruction\": \"\\n\".join([\n",
        "            \"# Story:\",\n",
        "            rec[\"story\"],\n",
        "\n",
        "            \"# Task:\",\n",
        "            rec[\"task\"],\n",
        "\n",
        "            \"# Output Scheme:\",\n",
        "            rec[\"output_scheme\"],\n",
        "            \"\",\n",
        "\n",
        "            \"# Output JSON:\",\n",
        "            \"```json\"\n",
        "\n",
        "        ]),\n",
        "        \"input\": \"\",\n",
        "        \"output\": \"\\n\".join([\n",
        "            \"```json\",\n",
        "            json.dumps(rec[\"response\"], ensure_ascii=False, default=str),\n",
        "            \"```\"\n",
        "        ]),\n",
        "        \"history\": []\n",
        "    })\n",
        "\n",
        "random.Random(101).shuffle(llm_finetunning_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef0f015a",
      "metadata": {
        "id": "ef0f015a"
      },
      "outputs": [],
      "source": [
        "llm_finetunning_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e54a9578",
      "metadata": {
        "id": "e54a9578"
      },
      "outputs": [],
      "source": [
        "llm_finetunning_data[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11cada0a",
      "metadata": {
        "id": "11cada0a"
      },
      "outputs": [],
      "source": [
        "len(llm_finetunning_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae1f9ead",
      "metadata": {
        "id": "ae1f9ead"
      },
      "outputs": [],
      "source": [
        "train_sample_sz = 2700\n",
        "\n",
        "train_ds = llm_finetunning_data[:train_sample_sz]\n",
        "eval_ds = llm_finetunning_data[train_sample_sz:]\n",
        "\n",
        "os.makedirs(join(\"Stories\", \"llamafactory-finetune-data\"), exist_ok=True)\n",
        "\n",
        "with open(join(\"Stories\", \"llamafactory-finetune-data\", \"train.json\"), \"w\" , encoding='utf-8') as dest:\n",
        "    json.dump(train_ds, dest, ensure_ascii=False, default=str)\n",
        "\n",
        "with open(join(\"Stories\", \"llamafactory-finetune-data\", \"val.json\"), \"w\", encoding=\"utf8\") as dest:\n",
        "    json.dump(eval_ds, dest, ensure_ascii=False, default=str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qgCsN4dF7IiY",
      "metadata": {
        "id": "qgCsN4dF7IiY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QJuboY_e7IwJ",
      "metadata": {
        "id": "QJuboY_e7IwJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6IvpoVO2jNf",
      "metadata": {
        "id": "d6IvpoVO2jNf"
      },
      "outputs": [],
      "source": [
        "# افتح الملف\n",
        "with open(\"/content/data/train.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ROCUS3qD2jPc",
      "metadata": {
        "id": "ROCUS3qD2jPc"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(batch):\n",
        "    prompts = [i + \"\\n\" + j for i, j in zip(batch[\"instruction\"], batch.get(\"input\", [\"\"]*len(batch[\"instruction\"])))]\n",
        "\n",
        "    # tokenize inputs\n",
        "    tokenized = tokenizer(\n",
        "        prompts,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # tokenize outputs (labels)\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            batch[\"output\"],\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            padding=\"max_length\",\n",
        "        )\n",
        "\n",
        "    tokenized[\"labels\"] = labels[\"input_ids\"]\n",
        "    return tokenized\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2HFmDMuG2jRJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "ff1c6147c0be4d19b00709829f44b74c",
            "2bdb239cbe344dc4b5ba2fa007e6382a",
            "cd98509785e54ca6822aa199aa9aec47",
            "a19a6d5e9ca8489fb90e89055f026f02",
            "4adcffa7cef14e29b65a0b4d86438fbd",
            "dac19164a5684ddbb930ad71d7406364",
            "7702072abcc845ce838e56ac26b47a66",
            "d6187457069b495b8d1c8ac3fa366f95",
            "b217a4b96dc748caba3e6f6ecbcb307f",
            "7bc22078ea5e469e98115a30e4b32b19",
            "b321558e1b2d4faaab5a1cc96f36e7e6"
          ]
        },
        "id": "2HFmDMuG2jRJ",
        "outputId": "a38270de-5eac-45a9-8a49-81743ee93b8a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff1c6147c0be4d19b00709829f44b74c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/2700 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:4118: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# حول list من dicts لـ Dataset\n",
        "train_dataset = Dataset.from_list(data)\n",
        "# val_dataset = Dataset.from_list(eval_ds)\n",
        "\n",
        "# طبق tokenize\n",
        "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
        "# tokenized_val = val_dataset.map(tokenize_function, batched=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iMWlc1DC2jVp",
      "metadata": {
        "id": "iMWlc1DC2jVp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a356d0e1",
      "metadata": {
        "id": "a356d0e1"
      },
      "source": [
        "## Finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BtEsD0wY7BSB",
      "metadata": {
        "id": "BtEsD0wY7BSB"
      },
      "source": [
        "## setup up lora_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46158ed2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46158ed2",
        "outputId": "bc449200-8117-4d59-c401-80729ab86ca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 2,179,072 || all params: 1,545,893,376 || trainable%: 0.1410\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig , get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\",  \"v_proj\" ] ,\n",
        "    lora_dropout=0.05 ,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model , lora_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TeD9Hu8Z7EvQ",
      "metadata": {
        "id": "TeD9Hu8Z7EvQ"
      },
      "source": [
        "## Tranning Lara"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J7Fcwecs2bqU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "J7Fcwecs2bqU",
        "outputId": "0de9887e-5db1-4f29-9189-c95255352b62"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251206_182330-5gjfo2f2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/omaryaser311-mansoura-university/huggingface/runs/5gjfo2f2' target=\"_blank\">brisk-feather-6</a></strong> to <a href='https://wandb.ai/omaryaser311-mansoura-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/omaryaser311-mansoura-university/huggingface' target=\"_blank\">https://wandb.ai/omaryaser311-mansoura-university/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/omaryaser311-mansoura-university/huggingface/runs/5gjfo2f2' target=\"_blank\">https://wandb.ai/omaryaser311-mansoura-university/huggingface/runs/5gjfo2f2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='26' max='171' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 26/171 31:54 < 3:12:44, 0.01 it/s, Epoch 0.44/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False,\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./fine_tunned_qwen2.5_story_parser\",\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=12,\n",
        "    learning_rate=2e-4,\n",
        "    num_train_epochs=3,\n",
        "    bf16=True,\n",
        "    save_steps=200,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_dataset=tokenized_train,\n",
        "    data_collator=data_collator,\n",
        "    args=training_args,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DKpYTkFZqq2b",
      "metadata": {
        "id": "DKpYTkFZqq2b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eUYApemEqq5A",
      "metadata": {
        "id": "eUYApemEqq5A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "Qa6xHjI2qzPe",
      "metadata": {
        "id": "Qa6xHjI2qzPe"
      },
      "source": [
        "##Fine Tunning Using Lora Factory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0FWdNgUqq7b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0FWdNgUqq7b",
        "outputId": "357728fc-a2e9-4fd7-b5df-ff70003e1f75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'LLaMA-Factory'...\n",
            "remote: Enumerating objects: 462, done.\u001b[K\n",
            "remote: Counting objects: 100% (462/462), done.\u001b[K\n",
            "remote: Compressing objects: 100% (367/367), done.\u001b[K\n",
            "remote: Total 462 (delta 120), reused 302 (delta 78), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (462/462), 5.16 MiB | 6.04 MiB/s, done.\n",
            "Resolving deltas: 100% (120/120), done.\n",
            "Obtaining file:///content/LLaMA-Factory\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers!=4.52.0,!=4.57.0,<=4.57.1,>=4.49.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets<=4.0.0,>=2.16.0 in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (4.0.0)\n",
            "Collecting accelerate<=1.11.0,>=1.3.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting peft<=0.17.1,>=0.14.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading peft-0.17.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting trl<=0.9.6,>=0.8.6 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting gradio<=5.45.0,>=4.38.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading gradio-5.45.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (3.10.0)\n",
            "Collecting tyro<0.9.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading tyro-0.8.14-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (0.8.1)\n",
            "Collecting numpy<2.0.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (1.16.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (0.2.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (0.12.0)\n",
            "Collecting modelscope>=1.14.0 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading modelscope-1.32.0-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: hf-transfer in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (0.1.9)\n",
            "Collecting safetensors<=0.5.3 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting fire (from llamafactory==0.9.4.dev0)\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (2.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (5.29.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (6.0.3)\n",
            "Collecting pydantic<=2.10.6 (from llamafactory==0.9.4.dev0)\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (0.38.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (0.118.3)\n",
            "Requirement already satisfied: sse-starlette in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (3.0.3)\n",
            "Collecting av (from llamafactory==0.9.4.dev0)\n",
            "  Downloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (0.11.0)\n",
            "Requirement already satisfied: propcache!=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llamafactory==0.9.4.dev0) (0.4.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (2.9.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (2025.3.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (4.12.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.2.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.0.0)\n",
            "Collecting gradio-client==1.13.0 (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0)\n",
            "  Downloading gradio_client-1.13.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.11.4)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.14.7)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.48.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (0.20.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (4.15.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.13.0->gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (15.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (2.9.0.post0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from modelscope>=1.14.0->llamafactory==0.9.4.dev0) (75.2.0)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.12/dist-packages (from modelscope>=1.14.0->llamafactory==0.9.4.dev0) (2.5.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->llamafactory==0.9.4.dev0) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<=2.10.6->llamafactory==0.9.4.dev0) (0.7.0)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic<=2.10.6->llamafactory==0.9.4.dev0)\n",
            "  Downloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.57.0,<=4.57.1,>=4.49.0->llamafactory==0.9.4.dev0) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers!=4.52.0,!=4.57.0,<=4.57.1,>=4.49.0->llamafactory==0.9.4.dev0) (0.22.1)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.12/dist-packages (from tyro<0.9.0->llamafactory==0.9.4.dev0) (0.17.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro<0.9.0->llamafactory==0.9.4.dev0) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro<0.9.0->llamafactory==0.9.4.dev0)\n",
            "  Downloading shtab-1.8.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn->llamafactory==0.9.4.dev0) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn->llamafactory==0.9.4.dev0) (0.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from fire->llamafactory==0.9.4.dev0) (3.2.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.0.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->llamafactory==0.9.4.dev0) (1.1.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf->llamafactory==0.9.4.dev0) (4.9.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (3.11)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.13.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.0.9)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (1.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa->llamafactory==0.9.4.dev0) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa->llamafactory==0.9.4.dev0) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7.0->llamafactory==0.9.4.dev0) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (3.4.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.4.dev0) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.4.dev0) (2.19.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa->llamafactory==0.9.4.dev0) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->librosa->llamafactory==0.9.4.dev0) (2.0.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (3.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (3.5.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio<=5.45.0,>=4.38.0->llamafactory==0.9.4.dev0) (1.5.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (6.7.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=4.0.0,>=2.16.0->llamafactory==0.9.4.dev0) (1.22.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->llamafactory==0.9.4.dev0) (2.23)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro<0.9.0->llamafactory==0.9.4.dev0) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate<=1.11.0,>=1.3.0->llamafactory==0.9.4.dev0) (1.3.0)\n",
            "Downloading accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.8/375.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.45.0-py3-none-any.whl (60.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.13.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading modelscope-1.32.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.17.1-py3-none-any.whl (504 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.9/504.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.9.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.8.14-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (40.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.8.0-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: llamafactory\n",
            "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llamafactory: filename=llamafactory-0.9.4.dev0-0.editable-py3-none-any.whl size=28941 sha256=6ab5594965fd79e3affc32b6199632b1f76b72e860b4e403c04f510d6aa7a76d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-39wj3bk4/wheels/68/8b/5e/52f9888e6a91a2651260d603137c052b925af896da6e32a3f7\n",
            "Successfully built llamafactory\n",
            "Installing collected packages: shtab, safetensors, pydantic-core, numpy, fire, av, pydantic, modelscope, tyro, gradio-client, transformers, gradio, accelerate, trl, peft, llamafactory\n",
            "  Attempting uninstall: safetensors\n",
            "    Found existing installation: safetensors 0.7.0\n",
            "    Uninstalling safetensors-0.7.0:\n",
            "      Successfully uninstalled safetensors-0.7.0\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.41.4\n",
            "    Uninstalling pydantic_core-2.41.4:\n",
            "      Successfully uninstalled pydantic_core-2.41.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.12.3\n",
            "    Uninstalling pydantic-2.12.3:\n",
            "      Successfully uninstalled pydantic-2.12.3\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.14.0\n",
            "    Uninstalling gradio_client-1.14.0:\n",
            "      Successfully uninstalled gradio_client-1.14.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.57.3\n",
            "    Uninstalling transformers-4.57.3:\n",
            "      Successfully uninstalled transformers-4.57.3\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.50.0\n",
            "    Uninstalling gradio-5.50.0:\n",
            "      Successfully uninstalled gradio-5.50.0\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.12.0\n",
            "    Uninstalling accelerate-1.12.0:\n",
            "      Successfully uninstalled accelerate-1.12.0\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.18.0\n",
            "    Uninstalling peft-0.18.0:\n",
            "      Successfully uninstalled peft-0.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "mcp 1.23.1 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.10.6 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-1.11.0 av-16.0.1 fire-0.7.1 gradio-5.45.0 gradio-client-1.13.0 llamafactory-0.9.4.dev0 modelscope-1.32.0 numpy-1.26.4 peft-0.17.1 pydantic-2.10.6 pydantic-core-2.27.2 safetensors-0.5.3 shtab-1.8.0 transformers-4.57.1 trl-0.9.6 tyro-0.8.14\n"
          ]
        }
      ],
      "source": [
        "!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n",
        "!cd LLaMA-Factory && pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u3OsZy7fowxv",
      "metadata": {
        "id": "u3OsZy7fowxv"
      },
      "outputs": [],
      "source": [
        "# # Configure LLaMA-Factory for the new datasets\n",
        "\n",
        "# # update /content/LLaMA-Factory/data/dataset_info.json and append\n",
        "# ```\n",
        "  #  \"news_finetune_train\": {\n",
        "  #       \"file_name\": \"/gdrive/MyDrive/youtube-resources/llm-finetuning/datasets/llamafactory-finetune-data/train.json\",\n",
        "  #       \"columns\": {\n",
        "  #           \"prompt\": \"instruction\",\n",
        "  #           \"query\": \"input\",\n",
        "  #           \"response\": \"output\",\n",
        "  #           \"system\": \"system\",\n",
        "  #           \"history\": \"history\"\n",
        "  #       }\n",
        "  #   },\n",
        "  #   \"news_finetune_val\": {\n",
        "  #       \"file_name\": \"/gdrive/MyDrive/youtube-resources/llm-finetuning/datasets/llamafactory-finetune-data/val.json\",\n",
        "  #       \"columns\": {\n",
        "  #           \"prompt\": \"instruction\",\n",
        "  #           \"query\": \"input\",\n",
        "  #           \"response\": \"output\",\n",
        "  #           \"system\": \"system\",\n",
        "  #           \"history\": \"history\"\n",
        "  #       }\n",
        "  #   }\n",
        "# ```\n",
        "\n",
        "# https://wandb.ai/mr-bakrianoo/llamafactory/runs/apwbkni9\n",
        "# https://wandb.ai/mr-bakrianoo/llamafactory/runs/c5tf0q90"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LvzikzGWow0J",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvzikzGWow0J",
        "outputId": "74441e56-b761-403a-eb5f-ff98913072d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/LLaMA-Factory/examples/train_lora/news_finetune.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/LLaMA-Factory/examples/train_lora/news_finetune.yaml\n",
        "\n",
        "### model\n",
        "model_name_or_path: Qwen/Qwen2.5-1.5B-Instruct\n",
        "trust_remote_code: true\n",
        "\n",
        "### method\n",
        "stage: sft\n",
        "do_train: true\n",
        "finetuning_type: lora\n",
        "lora_rank: 32\n",
        "lora_target: q_proj,v_proj\n",
        "\n",
        "### dataset\n",
        "dataset: news_finetune_train\n",
        "eval_dataset: news_finetune_val\n",
        "template: qwen\n",
        "cutoff_len: 3500\n",
        "max_samples: 100\n",
        "overwrite_cache: true\n",
        "preprocessing_num_workers: 16\n",
        "\n",
        "### output\n",
        "# resume_from_checkpoint: /gdrive/MyDrive/youtube-resources/llm-finetuning/models/checkpoint-1500\n",
        "output_dir: /content/drive/MyDrive/fine_tunning_qwenn\n",
        "logging_steps: 10\n",
        "save_steps: 25\n",
        "plot_loss: true\n",
        "# overwrite_output_dir: true\n",
        "\n",
        "### train\n",
        "per_device_train_batch_size: 1\n",
        "gradient_accumulation_steps: 4\n",
        "learning_rate: 1.0e-4\n",
        "num_train_epochs: 3.0\n",
        "lr_scheduler_type: cosine\n",
        "warmup_ratio: 0.1\n",
        "bf16: true\n",
        "ddp_timeout: 180000000\n",
        "\n",
        "### eval\n",
        "# val_size: 0.1\n",
        "per_device_eval_batch_size: 1\n",
        "eval_strategy: steps\n",
        "eval_steps: 50\n",
        "\n",
        "report_to: wandb\n",
        "run_name: newsx-finetune-llamafactory\n",
        "\n",
        "push_to_hub: true\n",
        "export_hub_model_id: \"OmarFadlallah/news-analyzer\"\n",
        "hub_private_repo: true\n",
        "hub_strategy: checkpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hgw5vXigow2i",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgw5vXigow2i",
        "outputId": "6c36038e-ca5f-445d-b1c5-4cf699865133"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-08 20:37:41.512030: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765226261.533716    5272 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765226261.539856    5272 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765226261.555442    5272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765226261.555468    5272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765226261.555472    5272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765226261.555476    5272 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-08 20:37:41.560154: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[INFO|2025-12-08 20:37:57] llamafactory.hparams.parser:468 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: torch.bfloat16\n",
            "[INFO|tokenization_utils_base.py:2095] 2025-12-08 20:37:57,731 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2095] 2025-12-08 20:37:57,731 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2095] 2025-12-08 20:37:57,731 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2095] 2025-12-08 20:37:57,731 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2095] 2025-12-08 20:37:57,731 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2095] 2025-12-08 20:37:57,731 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2095] 2025-12-08 20:37:57,731 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|tokenization_utils_base.py:2364] 2025-12-08 20:37:58,052 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "[INFO|configuration_utils.py:765] 2025-12-08 20:37:59,536 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
            "[INFO|configuration_utils.py:839] 2025-12-08 20:37:59,537 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"dtype\": \"bfloat16\",\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"layer_types\": [\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"transformers_version\": \"4.57.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2095] 2025-12-08 20:38:00,040 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2095] 2025-12-08 20:38:00,040 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2095] 2025-12-08 20:38:00,041 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2095] 2025-12-08 20:38:00,041 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2095] 2025-12-08 20:38:00,041 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2095] 2025-12-08 20:38:00,041 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2095] 2025-12-08 20:38:00,041 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|tokenization_utils_base.py:2364] 2025-12-08 20:38:00,370 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "[INFO|2025-12-08 20:38:00] llamafactory.data.loader:143 >> Loading dataset /content/data/train.json...\n",
            "Converting format of dataset (num_proc=16): 100% 100/100 [00:01<00:00, 99.05 examples/s]\n",
            "[INFO|2025-12-08 20:38:02] llamafactory.data.loader:143 >> Loading dataset /content/data/val.json...\n",
            "Converting format of dataset (num_proc=16): 100% 66/66 [00:01<00:00, 62.70 examples/s]\n",
            "Running tokenizer on dataset (num_proc=16): 100% 100/100 [00:12<00:00,  8.02 examples/s]\n",
            "training example:\n",
            "input_ids:\n",
            "[151644, 8948, 198, 2610, 525, 264, 6584, 451, 12567, 821, 6729, 624, 12480, 279, 3897, 1565, 6262, 63, 553, 279, 1196, 323, 279, 1565, 5097, 43781, 63, 311, 6923, 279, 1565, 5097, 4718, 18639, 5404, 537, 6923, 894, 16800, 476, 16688, 13, 151645, 198, 151644, 872, 198, 2, 15106, 510, 29825, 55334, 126458, 143507, 45577, 5703, 123860, 39423, 20064, 131723, 63237, 125007, 128538, 123877, 126385, 73441, 128416, 39434, 124837, 13325, 59842, 8532, 125192, 124766, 125559, 17166, 132748, 128769, 125766, 124006, 77273, 39434, 132579, 53710, 124267, 124114, 123987, 68785, 129943, 73274, 130527, 74315, 124522, 37524, 27490, 124179, 68238, 65398, 84532, 13, 715, 124766, 124283, 124543, 53479, 124322, 25871, 142734, 126655, 125007, 128305, 123877, 126385, 73441, 39434, 133498, 23364, 132137, 47632, 142734, 68785, 128248, 135638, 53479, 127172, 137499, 123877, 124636, 123890, 73441, 128562, 124006, 53479, 58656, 135430, 68785, 133950, 63415, 126385, 73441, 124265, 127467, 124080, 41593, 124636, 124072, 123904, 123963, 47632, 128405, 124837, 124082, 47632, 13, 715, 128388, 125007, 123877, 126385, 73441, 135087, 73441, 128718, 133020, 132070, 125434, 124514, 124082, 70604, 37524, 127799, 132070, 17166, 124480, 39423, 68785, 124838, 125481, 136510, 47632, 123894, 123860, 124766, 126385, 73441, 12961, 11071, 127476, 126815, 81778, 43635, 132033, 124766, 126385, 73441, 123961, 126019, 73441, 124072, 125916, 123832, 68785, 128416, 128510, 125077, 125709, 124130, 25871, 134017, 17166, 132748, 13, 715, 128827, 142201, 74315, 124522, 123961, 12653, 65398, 84532, 68785, 140880, 130283, 77703, 14558, 124346, 125143, 124226, 126350, 39434, 124104, 72804, 128305, 123877, 126385, 73441, 68785, 128259, 125027, 124009, 129919, 73274, 130151, 125637, 124678, 124476, 13325, 125646, 133843, 23224, 91344, 130519, 20931, 135542, 125701, 13, 715, 124838, 129013, 128443, 68785, 73274, 124464, 123860, 128248, 124793, 129843, 73274, 131744, 124793, 44330, 126924, 125007, 73274, 64604, 8532, 123995, 50243, 92381, 124653, 128248, 124080, 123941, 25871, 135276, 126208, 125215, 25871, 126198, 128754, 126214, 128280, 124220, 126924, 126298, 125007, 140620, 124661, 59842, 8532, 124671, 128248, 77703, 124144, 125011, 128248, 17166, 132748, 129521, 125559, 13, 715, 37524, 123860, 21360, 125313, 126899, 128707, 123862, 125653, 125007, 130616, 124261, 124220, 126924, 63237, 129193, 37524, 125657, 25871, 124665, 129636, 128259, 132338, 128636, 129581, 125490, 125108, 127930, 131351, 73441, 624, 2, 5430, 510, 2610, 614, 311, 14683, 279, 3364, 2213, 1119, 6364, 5815, 448, 264, 2265, 1119, 264, 4718, 624, 2, 9258, 43781, 510, 4913, 13193, 788, 5212, 53242, 6112, 788, 5212, 4684, 788, 330, 50, 53276, 24531, 2265, 315, 279, 3669, 3364, 10465, 330, 60992, 788, 220, 17, 20, 20, 11, 330, 1065, 4373, 788, 220, 20, 11, 330, 2102, 788, 330, 81016, 10869, 497, 330, 1313, 788, 330, 917, 14345, 330, 53242, 7495, 788, 5212, 4684, 788, 330, 81016, 2213, 315, 279, 3669, 3364, 10465, 330, 1065, 4373, 788, 220, 20, 11, 330, 2102, 788, 330, 81016, 8883, 497, 330, 1313, 788, 330, 917, 9207, 2137, 330, 6279, 788, 4383, 53242, 6112, 497, 330, 53242, 7495, 7914, 330, 2102, 788, 330, 81016, 17938, 497, 330, 1313, 788, 330, 1700, 63159, 2, 9258, 4718, 510, 73594, 2236, 151645, 198, 151644, 77091, 198, 73594, 2236, 198, 4913, 53242, 6112, 788, 330, 12087, 9975, 12566, 804, 362, 1705, 287, 52253, 18702, 497, 330, 53242, 7495, 788, 330, 78088, 3393, 14418, 702, 18683, 429, 1045, 29910, 1231, 39150, 279, 7149, 323, 4763, 315, 9842, 4152, 311, 22706, 12720, 3039, 11, 7703, 279, 5214, 315, 32688, 13, 576, 5938, 14418, 11247, 429, 1493, 29910, 2924, 6646, 58544, 3004, 11, 1741, 438, 83360, 1075, 26351, 482, 11, 438, 1632, 438, 91881, 29910, 11, 21127, 25097, 11, 323, 10923, 5859, 13, 22406, 11, 46557, 29910, 1075, 64111, 1783, 323, 3196, 3077, 5641, 49903, 11, 3654, 7912, 21025, 11, 6543, 7262, 29910, 11, 323, 59654, 323, 19754, 29910, 1231, 17040, 5322, 1393, 9842, 13, 2014, 5648, 279, 5214, 315, 32688, 11, 825, 1265, 537, 6541, 1393, 4633, 1493, 29910, 11, 5310, 979, 8266, 84084, 11, 294, 1811, 88, 11, 476, 3432, 16829, 75287, 13, 758, 4586, 11, 5489, 4633, 894, 23221, 1265, 1779, 279, 15933, 1149, 311, 1490, 421, 279, 23221, 1410, 47191, 7802, 862, 5726, 311, 6541, 21000, 13, 1084, 1265, 1083, 387, 10342, 429, 279, 18048, 315, 264, 23221, 916, 279, 5546, 1558, 537, 3076, 432, 702, 902, 3108, 6239, 1189, 532, 73594, 151645, 198]\n",
            "inputs:\n",
            "<|im_start|>system\n",
            "You are a professional NLP data parser.\n",
            "Follow the provided `Task` by the user and the `Output Scheme` to generate the `Output JSON`.\n",
            "Do not generate any introduction or conclusion.<|im_end|>\n",
            "<|im_start|>user\n",
            "# Story:\n",
            "حذرت مجلة فاينانس تست من أن بعض الأدوية قد تهدد سلامة وأمان القيادة لتسببها في تأخر ردة الفعل، مما يرفع خطر وقوع حادث. \n",
            " وأوضحت المجلة الألمانية أن هذه الأدوية تشمل مسكنات الألم، على سبيل المثال المواد الأفيونية ومنها المورفين، وكذلك أدوية الصداع النصفي والمنومات والمهدئات. \n",
            " كما أن الأدوية النفسية مثل مضادات الاكتئاب ومضادات الذهان، وبعض قطرات العين وأدوية ارتفاع ضغط الدم وأدوية الحساسية والسكري، قد تمثل مشكلة أثناء القيادة. \n",
            " ولتجنب خطر الحوادث، ينبغي عدم قيادة السيارة عند تناول هذه الأدوية، لا سيما عندما يشعر المرء بالدوار والنعاس وضعف التركيز. \n",
            " وبشكل عام، يتعين على أي شخص يتناول أي دواء أن يُلقي نظرة على النشرة الداخلية لمعرفة ما إذا كان هذا الدواء يمكن أن يؤثر سلبا على قدرته على القيادة بأمان. \n",
            " وينبغي أيضا مراعاة أن توفر الدواء من دون وصفة طبية لا يعني أنه ليس له آثار جانبية.\n",
            "# Task:\n",
            "You have to translate the story content into English associated with a title into a JSON.\n",
            "# Output Scheme:\n",
            "{\"properties\": {\"translated_title\": {\"description\": \"Suggested translated title of the news story.\", \"maxLength\": 255, \"minLength\": 5, \"title\": \"Translated Title\", \"type\": \"string\"}, \"translated_content\": {\"description\": \"Translated content of the news story.\", \"minLength\": 5, \"title\": \"Translated Content\", \"type\": \"string\"}}, \"required\": [\"translated_title\", \"translated_content\"], \"title\": \"TranslatedStory\", \"type\": \"object\"}\n",
            "\n",
            "# Output JSON:\n",
            "```json<|im_end|>\n",
            "<|im_start|>assistant\n",
            "```json\n",
            "{\"translated_title\": \"Warning About Medications Affecting Driving Safety\", \"translated_content\": \"Finance Test magazine has warned that some medications may threaten the safety and security of driving due to delayed reaction times, increasing the risk of accidents. The German magazine explained that these medications include pain relievers, such as opioids like morphine, as well as migraine medications, sleeping pills, and sedatives. Additionally, psychiatric medications like antidepressants and antipsychotics, certain eye drops, blood pressure medications, and allergy and diabetes medications may pose problems while driving. To avoid the risk of accidents, one should not drive while taking these medications, especially when feeling dizzy, drowsy, or having difficulty concentrating. In general, anyone taking any medication should check the leaflet to see if the medication could negatively affect their ability to drive safely. It should also be noted that the availability of a medication over the counter does not mean it has no side effects.\"}\n",
            "```<|im_end|>\n",
            "\n",
            "label_ids:\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 73594, 2236, 198, 4913, 53242, 6112, 788, 330, 12087, 9975, 12566, 804, 362, 1705, 287, 52253, 18702, 497, 330, 53242, 7495, 788, 330, 78088, 3393, 14418, 702, 18683, 429, 1045, 29910, 1231, 39150, 279, 7149, 323, 4763, 315, 9842, 4152, 311, 22706, 12720, 3039, 11, 7703, 279, 5214, 315, 32688, 13, 576, 5938, 14418, 11247, 429, 1493, 29910, 2924, 6646, 58544, 3004, 11, 1741, 438, 83360, 1075, 26351, 482, 11, 438, 1632, 438, 91881, 29910, 11, 21127, 25097, 11, 323, 10923, 5859, 13, 22406, 11, 46557, 29910, 1075, 64111, 1783, 323, 3196, 3077, 5641, 49903, 11, 3654, 7912, 21025, 11, 6543, 7262, 29910, 11, 323, 59654, 323, 19754, 29910, 1231, 17040, 5322, 1393, 9842, 13, 2014, 5648, 279, 5214, 315, 32688, 11, 825, 1265, 537, 6541, 1393, 4633, 1493, 29910, 11, 5310, 979, 8266, 84084, 11, 294, 1811, 88, 11, 476, 3432, 16829, 75287, 13, 758, 4586, 11, 5489, 4633, 894, 23221, 1265, 1779, 279, 15933, 1149, 311, 1490, 421, 279, 23221, 1410, 47191, 7802, 862, 5726, 311, 6541, 21000, 13, 1084, 1265, 1083, 387, 10342, 429, 279, 18048, 315, 264, 23221, 916, 279, 5546, 1558, 537, 3076, 432, 702, 902, 3108, 6239, 1189, 532, 73594, 151645, 198]\n",
            "labels:\n",
            "```json\n",
            "{\"translated_title\": \"Warning About Medications Affecting Driving Safety\", \"translated_content\": \"Finance Test magazine has warned that some medications may threaten the safety and security of driving due to delayed reaction times, increasing the risk of accidents. The German magazine explained that these medications include pain relievers, such as opioids like morphine, as well as migraine medications, sleeping pills, and sedatives. Additionally, psychiatric medications like antidepressants and antipsychotics, certain eye drops, blood pressure medications, and allergy and diabetes medications may pose problems while driving. To avoid the risk of accidents, one should not drive while taking these medications, especially when feeling dizzy, drowsy, or having difficulty concentrating. In general, anyone taking any medication should check the leaflet to see if the medication could negatively affect their ability to drive safely. It should also be noted that the availability of a medication over the counter does not mean it has no side effects.\"}\n",
            "```<|im_end|>\n",
            "\n",
            "Running tokenizer on dataset (num_proc=16): 100% 66/66 [00:12<00:00,  5.35 examples/s]\n",
            "eval example:\n",
            "input_ids:\n",
            "[151644, 8948, 198, 2610, 525, 264, 6584, 451, 12567, 821, 6729, 624, 12480, 279, 3897, 1565, 6262, 63, 553, 279, 1196, 323, 279, 1565, 5097, 43781, 63, 311, 6923, 279, 1565, 5097, 4718, 18639, 5404, 537, 6923, 894, 16800, 476, 16688, 13, 151645, 198, 151644, 872, 198, 2, 15106, 510, 129714, 131801, 27846, 130950, 77273, 39434, 123890, 20064, 68785, 128374, 123877, 136176, 124280, 124172, 125767, 25871, 129744, 73441, 68785, 126195, 93153, 124388, 31382, 137024, 142887, 126510, 68785, 131933, 123894, 129600, 77273, 129458, 124636, 55334, 77703, 11071, 124669, 126453, 5703, 124613, 68785, 131933, 44330, 125138, 130771, 124072, 132970, 68785, 131933, 126453, 128559, 124325, 123894, 65398, 128518, 68785, 129673, 128248, 74315, 124284, 73441, 124012, 129600, 124172, 125591, 126212, 138928, 140765, 125006, 127570, 47632, 124072, 134700, 124058, 125573, 73441, 68785, 133707, 77703, 11071, 124669, 128305, 134515, 128261, 126815, 124011, 14293, 128794, 138928, 43982, 125516, 123961, 123829, 43635, 13, 715, 12961, 133326, 14293, 124080, 125940, 143825, 20064, 73441, 125007, 124058, 127524, 47632, 130771, 73441, 128261, 63415, 125150, 14293, 129387, 68238, 125229, 47632, 126198, 128325, 124437, 125520, 68785, 63237, 128374, 44330, 46586, 58656, 220, 17, 15, 16, 19, 68785, 128416, 27846, 47632, 14293, 130656, 127837, 23364, 125154, 123963, 127837, 128464, 131132, 131037, 127923, 131045, 13, 129828, 130519, 53479, 123941, 73771, 135590, 68785, 128325, 142402, 126409, 47632, 23364, 35038, 124352, 123890, 73441, 139412, 12961, 10176, 125645, 14293, 129225, 125849, 135376, 132351, 68785, 128962, 20064, 126453, 128559, 124325, 123894, 65398, 128518, 37524, 136341, 124006, 132294, 126483, 93543, 124006, 131936, 129200, 84996, 126413, 13, 128478, 125007, 126731, 124330, 14558, 55891, 126931, 138752, 126196, 77703, 131910, 126453, 31073, 124325, 124058, 125573, 73441, 68785, 63415, 129714, 17166, 130076, 128252, 137623, 124265, 124261, 68785, 124766, 141068, 55057, 125696, 130170, 123862, 126513, 133483, 39434, 129989, 27846, 124938, 55057, 125069, 130741, 25871, 128252, 124147, 124284, 68785, 27846, 129600, 127837, 63237, 123894, 125629, 13, 715, 128474, 14293, 126453, 31073, 124325, 124058, 125573, 73441, 124665, 135590, 135377, 128707, 32790, 133955, 125006, 127570, 47632, 124269, 124082, 91344, 73441, 68785, 37524, 124621, 126458, 85153, 126415, 123862, 124138, 128252, 123913, 21360, 124181, 138751, 14558, 68785, 23364, 130353, 73441, 137007, 77703, 11071, 124669, 138928, 128261, 128962, 124687, 129080, 135172, 130995, 77703, 126968, 14558, 124838, 125343, 73771, 47632, 37524, 124642, 73441, 68785, 128388, 37524, 125657, 128349, 125637, 32790, 29825, 123890, 127560, 25871, 68785, 127555, 124009, 50243, 41593, 128471, 131695, 14558, 127837, 77703, 131910, 126453, 31073, 124325, 13, 715, 128641, 124009, 39434, 125169, 124269, 69682, 14558, 128586, 77273, 135275, 124072, 129609, 68785, 124072, 126119, 127221, 133527, 123890, 68785, 93153, 124082, 11798, 95975, 125637, 32790, 133955, 126208, 124703, 124138, 131695, 125358, 124837, 138751, 14558, 86941, 123904, 95975, 125838, 82168, 79820, 123860, 125006, 133063, 77703, 124392, 59842, 125090, 73771, 13325, 68785, 127955, 16157, 73441, 128464, 131651, 68785, 129869, 137204, 56794, 127570, 47632, 141396, 63237, 63415, 124514, 130945, 133205, 124665, 124423, 127837, 128402, 124169, 27490, 127837, 68785, 131813, 77703, 131910, 55891, 126931, 138752, 126502, 125106, 127837, 125006, 131610, 68785, 63237, 128374, 124058, 124363, 39423, 77273, 85153, 125669, 98719, 125637, 32790, 133955, 127560, 25871, 13, 715, 128280, 134466, 126214, 128763, 84532, 125275, 127726, 136666, 63415, 124014, 77273, 132745, 130519, 12961, 124126, 35244, 70604, 14558, 82168, 65398, 73274, 57859, 123904, 23364, 129614, 39434, 127809, 124035, 142847, 124072, 124706, 95975, 20064, 124080, 125089, 16157, 68785, 37524, 124438, 131032, 63237, 94957, 132119, 129755, 123904, 14558, 126212, 123894, 125152, 47632, 132793, 128248, 94957, 29825, 32790, 123980, 74315, 124284, 128707, 32790, 29825, 126761, 128577, 56794, 57859, 125559, 85153, 127878, 94957, 125313, 93543, 128307, 128657, 133548, 132674, 86941, 84532, 14558, 132280, 68785, 128523, 129445, 124082, 31073, 129174, 12961, 41593, 125346, 123920, 74315, 124284, 128295, 124388, 70604, 220, 17, 20, 135621, 123978, 124412, 220, 17, 15, 17, 16, 68785, 130117, 123920, 63237, 128773, 53479, 139600, 129249, 131045, 68785, 124072, 127099, 127116, 128883, 130881, 47632, 124072, 124938, 124691, 128261, 12961, 14293, 64604, 73771, 137867, 14293, 56794, 124210, 27490, 127837, 68785, 129833, 73274, 125657, 124006, 74315, 140636, 126543, 77703, 124392, 59842, 125090, 73771, 13325, 27846, 124074, 31382, 124341, 124187, 133642, 124072, 13325, 124514, 47632, 126113, 13, 715, 133431, 12961, 27490, 124706, 23224, 63415, 125718, 21360, 55891, 124035, 129899, 126513, 73771, 94957, 125313, 93543, 23364, 125493, 68785, 126420, 128321, 126815, 11071, 125729, 13, 715, 77703, 131910, 55891, 126931, 138752, 128280, 39434, 125766, 77273, 59842, 95198, 43982, 35038, 10176, 63237, 17166, 124519, 27490, 132070, 143098, 55334, 124511, 68785, 92072, 124144, 14293, 126195, 139589, 77703, 126968, 37524, 142539, 125027, 91344, 73441, 124766, 129895, 70604, 128562, 125362, 47632, 68785, 37524, 141470, 133547, 73441, 77273, 135275, 124072, 129609, 13, 37524, 123978, 37524, 125657, 16157, 27846, 124074, 31382, 124464, 20064, 124636, 131795, 125669, 124863, 124072, 133672, 124641, 56794, 133063, 129814, 134898, 13, 126420, 12961, 129080, 14293, 138928, 27846, 134681, 124006, 128252, 63415, 124405, 25871, 132266, 137024, 140597, 55334, 73441, 68785, 129869, 63415, 129152, 91335, 5703, 93153, 124388, 124421, 128412, 68785, 138827, 23364, 41593, 124405, 123995, 128412, 68785, 37524, 11798, 130030, 134035, 92072, 126413, 133612, 65398, 128261, 43982, 64604, 126780, 14293, 128794, 138928, 129185, 85153, 124983, 98719, 129445, 50243, 20064, 35244, 25871, 129431, 77273, 128586, 220, 17, 15, 16, 16, 68785, 27846, 134736, 129445, 12961, 124126, 35244, 70604, 47632, 39434, 130910, 73441, 68238, 127347, 73441, 77273, 133483, 68785, 85153, 21360, 73771, 39423, 125069, 125520, 220, 16, 19, 134340, 124703, 123890, 130277, 220, 17, 15, 16, 16, 13, 715, 12961, 136204, 53479, 124668, 43635, 133527, 124072, 126123, 123938, 39434, 127923, 127837, 63237, 138928, 128577, 56794, 57859, 125559, 52157, 20931, 133176, 138752, 37524, 130163, 124642, 128412, 68785, 128762, 128305, 134515, 63415, 124148, 14293, 128248, 138990, 124006, 13, 37524, 129883, 128755, 124006, 68785, 45577, 35038, 124085, 27846, 124179, 126023, 68785, 125502, 127207, 23364, 136596, 127837, 93153, 124122, 35038, 85153, 125669, 98719, 125637, 32790, 133955, 127560, 25871, 131268, 65398, 124220, 5703, 135063, 68785, 128562, 127188, 125572, 124104, 133065, 68785, 37524, 136961, 124478, 43635, 124394, 53479, 124811, 13, 37524, 127029, 12961, 125011, 49388, 127837, 128883, 128074, 124325, 124058, 125573, 73441, 27846, 124343, 27490, 124058, 124328, 98719, 47632, 130771, 73441, 68785, 124209, 135425, 128307, 50243, 20931, 125011, 126453, 31073, 124325, 50243, 124636, 127837, 77703, 124330, 23224, 127837, 68785, 129353, 43982, 125516, 37524, 84532, 125955, 39434, 132596, 59842, 8532, 125192, 85153, 124328, 98719, 130377, 37524, 124938, 124691, 124006, 37524, 129152, 127837, 125006, 130718, 128405, 124322, 25871, 141912, 126510, 125088, 92381, 124325, 56794, 125523, 126453, 31073, 124325, 128402, 124944, 47632, 39434, 129955, 124006, 13, 715, 128641, 129163, 126556, 128546, 124042, 124325, 63237, 128280, 17166, 137378, 124080, 126409, 124082, 68785, 56794, 33090, 127477, 128538, 123877, 124522, 95975, 77273, 133483, 128252, 127115, 124420, 125653, 55891, 126931, 138752, 68785, 82611, 124675, 124422, 124006, 39434, 124423, 73771, 131922, 39434, 129422, 124412, 137024, 68785, 130444, 39434, 125267, 27846, 124621, 124669, 124012, 128026, 140425, 130462, 126453, 31073, 52704, 73771, 124325, 77273, 137637, 138751, 73441, 68785, 129308, 126453, 31073, 124325, 124058, 125573, 73441, 68785, 128261, 138073, 73771, 63415, 128074, 49388, 124006, 27846, 47632, 73771, 25871, 37524, 124647, 126510, 68785, 124793, 128478, 77703, 127415, 25871, 125006, 43635, 127206, 128264, 124058, 130353, 98719, 68785, 37524, 129152, 45577, 132412, 98719, 130771, 124072, 135617, 25871, 124058, 125573, 126319, 68785, 128718, 124172, 124420, 14558, 124058, 125573, 14558, 129200, 127818, 131118, 92072, 127602, 68785, 128307, 53710, 124898, 27846, 129345, 16157, 44330, 23224, 125187, 134541, 126510, 130160, 138928, 68785, 27846, 131271, 16157, 142685, 124723, 127837, 50243, 5703, 125940, 127837, 68785, 132402, 27846, 125657, 125011, 142887, 126510, 13, 715, 128671, 141183, 126453, 31073, 124325, 124058, 125573, 73441, 128261, 63415, 64604, 124983, 137648, 128586, 220, 16, 24, 22, 17, 129458, 142641, 77273, 142001, 17166, 125664, 73771, 77273, 44330, 125072, 125187, 39434, 129422, 124412, 137024, 68785, 128261, 129106, 53710, 124898, 124006, 131425, 130353, 98719, 23364, 124621, 125815, 85153, 125573, 73441, 68785, 128474, 125007, 129106, 126731, 127616, 124172, 126277, 123860, 125088, 92381, 124325, 129046, 128443, 220, 17, 15, 16, 19, 68785, 27846, 47632, 33090, 124642, 85153, 125629, 70604, 124006, 23364, 125930, 127837, 63237, 126455, 124388, 125756, 68785, 128562, 29825, 124006, 123894, 125123, 73441, 77273, 77703, 11071, 124669, 124006, 68785, 74315, 41593, 125155, 127837, 77273, 124080, 39697, 123862, 47632, 138751, 73441, 68785, 129869, 137204, 129046, 132371, 73441, 128248, 127072, 35038, 138751, 14558, 73771, 13, 715, 128478, 125007, 55891, 126931, 138752, 53710, 127477, 74315, 125395, 128349, 138787, 127837, 13, 129828, 128707, 73771, 81778, 14293, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 77273, 94957, 127106, 68785, 37524, 126666, 14293, 129431, 128420, 124130, 127837, 134933, 53710, 128722, 68785, 23364, 123987, 124282, 12961, 124543, 126900, 124006, 132371, 73441, 128248, 138752, 37524, 124223, 124669, 124006, 136973, 68785, 63237, 85153, 123987, 39423, 130570, 124006, 128252, 124058, 123987, 39423, 126195, 50243, 14293, 123829, 33090, 124006, 124080, 16157, 126510, 13, 715, 126731, 124466, 55891, 126931, 138752, 126196, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 73274, 126624, 133483, 128252, 137623, 124265, 124261, 68785, 129943, 63415, 127930, 23364, 35244, 5703, 124387, 128967, 93153, 124388, 31382, 124172, 127288, 37524, 130163, 124642, 25871, 137637, 138751, 73441, 715, 37524, 11071, 126106, 124012, 129600, 128307, 126208, 73274, 138210, 52704, 128252, 129968, 126212, 127647, 20064, 46586, 123860, 68785, 128843, 124080, 124787, 125168, 131205, 68785, 129308, 85153, 125669, 98719, 125637, 32790, 133955, 127560, 25871, 68785, 131795, 140478, 128248, 127560, 14558, 53479, 127207, 129185, 17166, 135911, 73441, 126543, 77703, 124392, 59842, 125090, 73771, 13325, 68785, 126857, 16157, 93543, 53479, 81778, 130010, 124623, 126418, 123860, 128443, 68238, 126703, 129839, 68785, 132525, 124075, 128862, 125572, 125291, 128755, 68238, 126703, 43982, 124641, 131482, 128307, 63415, 64604, 129955, 123913, 126336, 23364, 124085, 124387, 127837, 128577, 130153, 82168, 11071, 125591, 39434, 13325, 127300, 94957, 39697, 124811, 47632, 129839, 73441, 68785, 68238, 124125, 12961, 125011, 49388, 137024, 125490, 13, 715, 129581, 128280, 37524, 129523, 68785, 126420, 59842, 35038, 124675, 137024, 140597, 55334, 73441, 128252, 50243, 123941, 77703, 131910, 138928, 131695, 124012, 123832, 124267, 124269, 124131, 73441, 125006, 135463, 143825, 20064, 73441, 128577, 56794, 130389, 132866, 130063, 124793, 63415, 124014, 77273, 123894, 69423, 25871, 128252, 17166, 58656, 98719, 68785, 128388, 73274, 11071, 124848, 126543, 59842, 125090, 73771, 13325, 136075, 127837, 13, 715, 126420, 128342, 137024, 68785, 23364, 31073, 124126, 55891, 126931, 138752, 63237, 52157, 29825, 124282, 123961, 83827, 138751, 14558, 68785, 129271, 124811, 91344, 125700, 123904, 25871, 68785, 130245, 129521, 58656, 124181, 17166, 124181, 124015, 123862, 68785, 77273, 139268, 23364, 129806, 134470, 137410, 68785, 126513, 130656, 125637, 32790, 133955, 127560, 25871, 129174, 63415, 124148, 14293, 138928, 128248, 85153, 20064, 27490, 124330, 39434, 129104, 29825, 124138, 125006, 127570, 47632, 124269, 124082, 91344, 73441, 128416, 68238, 64604, 124131, 128953, 128259, 53710, 33090, 124511, 128985, 68785, 129265, 74315, 125633, 55891, 126931, 138752, 126214, 59842, 125260, 127837, 128562, 43635, 123995, 127837, 68785, 77273, 133114, 125237, 137024, 13, 715, 124072, 132777, 68785, 134436, 128305, 53479, 124653, 130528, 128261, 129106, 128857, 53710, 124851, 129458, 124636, 55334, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 13, 129828, 59842, 125173, 56794, 133501, 123894, 129600, 125007, 53710, 124851, 14293, 128264, 39434, 81778, 124420, 14293, 126195, 129458, 124636, 55334, 68238, 124613, 126453, 31073, 124325, 124058, 125573, 73441, 130394, 125106, 31382, 77703, 131910, 85153, 23224, 132157, 124172, 125259, 25871, 220, 19, 24, 63237, 63415, 124224, 220, 20, 22, 77703, 124420, 14558, 127837, 68785, 128307, 12961, 14293, 64604, 73771, 137867, 128763, 133810, 130656, 53710, 124082, 125309, 77273, 135333, 129895, 129194, 220, 17, 15, 17, 17, 13, 715, 126208, 39434, 124232, 69682, 131209, 123894, 129600, 27846, 130076, 55891, 124035, 129899, 124172, 125259, 25871, 68785, 128523, 128325, 44330, 35244, 72804, 124138, 77273, 85153, 125248, 70604, 37524, 29825, 128862, 73771, 126195, 140591, 93153, 124122, 73771, 56794, 124079, 25871, 133674, 68785, 130444, 39434, 8532, 124880, 14293, 128252, 77703, 131910, 126453, 31073, 124325, 124058, 125573, 73441, 13, 126420, 123877, 91335, 55057, 63237, 128349, 68785, 125007, 55891, 124035, 129899, 124172, 125259, 25871, 126198, 73274, 130234, 123890, 128523, 128438, 134689, 23364, 139191, 47632, 134541, 126510, 63237, 128474, 137024, 68785, 56794, 130110, 49388, 124138, 126436, 11798, 73771, 85153, 125248, 70604, 37524, 124464, 43635, 95198, 23364, 126780, 27490, 85153, 125573, 14558, 131268, 123963, 14558, 135172, 130995, 126906, 13, 715, 128523, 125088, 125362, 47632, 136355, 128261, 39434, 39697, 124423, 44330, 126119, 124006, 126195, 130771, 124072, 127614, 126212, 138355, 68785, 128248, 125040, 131910, 131534, 128586, 143826, 125006, 138391, 125088, 92381, 124325, 132474, 70604, 73441, 123877, 124273, 27490, 77273, 39434, 123890, 20064, 68785, 53710, 124851, 14293, 124058, 55334, 134056, 56794, 129305, 126453, 31073, 124325, 124058, 125573, 73441, 142740, 128474, 27846, 57859, 124511, 128962, 70604, 124280, 68785, 56794, 126692, 29825, 128707, 124937, 53710, 27490, 125275, 126208, 127809, 124290, 124114, 20064, 65398, 68785, 128307, 128657, 39697, 124423, 16157, 125637, 32790, 29825, 56794, 11071, 124082, 91344, 25871, 140779, 126113, 68785, 131268, 65398, 124220, 5703, 135063, 13, 715, 130267, 126198, 126731, 124404, 130622, 126453, 31073, 124325, 124058, 125573, 73441, 129185, 43982, 136692, 13, 131649, 128342, 124478, 128655, 124678, 136709, 59842, 125750, 128402, 141905, 68785, 128762, 17166, 124210, 125492, 49388, 128252, 77703, 11071, 124669, 124006, 124766, 128074, 49388, 124006, 77273, 45577, 57859, 73771, 124080, 39697, 123862, 47632, 68785, 126198, 73274, 130234, 126815, 23224, 124394, 127837, 68785, 128342, 126208, 50243, 124388, 63237, 124079, 10176, 127837, 13, 130267, 126198, 73274, 134224, 59842, 124035, 31382, 127837, 82168, 129094, 123832, 127837, 128967, 63415, 124125, 70604, 37524, 126385, 123862, 14558, 130283, 129458, 124636, 55334, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 68785, 128248, 139066, 63237, 128288, 124265, 80970, 124668, 47632, 128261, 23364, 64604, 11798, 124543, 129046, 13, 715, 77273, 76841, 91344, 25871, 130226, 73441, 77703, 126968, 73441, 50243, 64604, 123941, 14293, 133427, 124343, 127837, 128967, 129458, 124636, 55334, 63415, 128074, 49388, 37524, 124621, 124669, 124172, 127288, 124058, 125573, 14558, 77273, 39434, 123890, 20064, 68785, 63415, 124347, 124172, 124420, 14558, 124058, 125573, 14558, 68785, 131268, 65398, 125110, 70604, 123832, 68785, 128252, 126198, 128962, 124009, 124006, 39434, 133172, 10176, 8803, 116, 127706, 130283, 129458, 124636, 55334, 63415, 128074, 49388, 124172, 127288, 124058, 125573, 14558, 68785, 128523, 133455, 73274, 64604, 11798, 124675, 124476, 133812, 128307, 128259, 39434, 64604, 139178, 63415, 128074, 49388, 16157, 37524, 124621, 124669, 16157, 68785, 129308, 124012, 124014, 25871, 128261, 39434, 141707, 77273, 133474, 128248, 128858, 123877, 130211, 11798, 77273, 39434, 123890, 20064, 68785, 86941, 135328, 25871, 130759, 128248, 128305, 124478, 49388, 127472, 125653, 128261, 39434, 131377, 128794, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 496, 56794, 49388, 127472, 125653, 39434, 125704, 128438, 126492, 125267, 124172, 127288, 124058, 125573, 14558, 128248, 86941, 20931, 73771, 43982, 52704, 20931, 123832, 14293, 13, 715, 126208, 73274, 138210, 52704, 132474, 126409, 126350, 130283, 129458, 124636, 55334, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 68785, 128342, 124009, 138073, 73771, 124642, 125502, 133498, 23364, 134363, 25871, 132371, 73441, 128248, 127072, 35038, 138751, 14558, 68785, 37524, 124438, 39434, 124223, 31073, 126453, 31073, 124325, 129521, 29825, 123995, 128412, 130771, 73441, 128248, 128280, 130208, 13, 128762, 55891, 126931, 138752, 128671, 128416, 59842, 125173, 14293, 136656, 128252, 128349, 129185, 17166, 135911, 73441, 68785, 63237, 128374, 85153, 123987, 39423, 128464, 133624, 124476, 31073, 124466, 128248, 137637, 138751, 73441, 13, 715, 137687, 53479, 124062, 124267, 56794, 11071, 130025, 125192, 138752, 68785, 129308, 63237, 39434, 131731, 130570, 128587, 17166, 124181, 124015, 123862, 68785, 129308, 63237, 39434, 133033, 128248, 130759, 94957, 41593, 124623, 14293, 68785, 128562, 39434, 127207, 126195, 50243, 14293, 123829, 124649, 124080, 16157, 126510, 13, 126857, 65398, 14293, 128248, 128349, 68785, 126513, 131694, 43635, 14293, 129225, 124434, 124006, 126906, 132371, 73441, 128248, 132919, 124072, 132970, 132919, 73441, 68785, 126420, 128523, 128248, 138324, 132919, 73441, 125637, 32790, 124290, 125006, 134971, 73771, 68785, 131247, 126198, 73274, 64604, 124676, 77273, 128538, 125088, 136077, 132919, 73441, 68785, 74315, 41593, 125155, 127837, 17166, 124519, 27490, 132070, 128261, 39434, 124146, 73771, 16157, 128252, 138928, 13, 715, 129581, 128280, 37524, 129523, 68785, 126420, 128342, 55891, 126931, 138752, 63415, 123987, 124126, 128464, 133624, 128248, 23364, 124347, 124571, 125088, 125362, 47632, 53479, 124233, 126987, 77273, 23364, 123940, 124572, 25871, 138752, 68785, 128718, 63237, 125362, 14293, 27910, 14558, 132823, 73274, 27490, 92381, 128402, 123940, 124572, 123890, 68785, 37524, 132621, 125011, 124009, 124476, 124434, 65398, 53479, 124421, 68785, 125449, 98719, 124376, 128248, 126198, 77703, 125962, 128342, 124006, 85153, 126123, 124669, 63237, 141405, 124269, 124131, 73441, 27846, 134440, 128920, 128248, 39434, 124453, 95198, 63415, 126336, 123938, 13, 128280, 132338, 125007, 138928, 93153, 125849, 55334, 14293, 128523, 128248, 129366, 124172, 127288, 68785, 53479, 35244, 72804, 37524, 29825, 91335, 27846, 137321, 128264, 50243, 124636, 39434, 124138, 25871, 124114, 20064, 65398, 53479, 124421, 128248, 125088, 125362, 128885, 13, 715, 128280, 124080, 39697, 124179, 125006, 126992, 123904, 25871, 128248, 137637, 138751, 73441, 68785, 132178, 124876, 65398, 126453, 31073, 124325, 124058, 125573, 73441, 63237, 131132, 47632, 136837, 138065, 124006, 125088, 41593, 125155, 129387, 77703, 126968, 127837, 77273, 140691, 124476, 127570, 47632, 68785, 82168, 130362, 130684, 63237, 131997, 98719, 124766, 20064, 47632, 55334, 25871, 130771, 73274, 129883, 123890, 126195, 92072, 126406, 124138, 68785, 128306, 124232, 73771, 132280, 126195, 53710, 124851, 124138, 128349, 27846, 124283, 128722, 13, 715, 129828, 12961, 126020, 123877, 46586, 125908, 86941, 125291, 125449, 23364, 20064, 124915, 68785, 128631, 127564, 77273, 124172, 127288, 124058, 125573, 14558, 68785, 125007, 126453, 31073, 124325, 124058, 125573, 73441, 39434, 137427, 124476, 126897, 73441, 140286, 25871, 128248, 138752, 68785, 74315, 41593, 125155, 127837, 77273, 124080, 39697, 123862, 47632, 138751, 73441, 129271, 128074, 49388, 142887, 126510, 126249, 47632, 73771, 25871, 124265, 65398, 124653, 134035, 68785, 128660, 126198, 63415, 31073, 91335, 128912, 63237, 53479, 138611, 123860, 77273, 130771, 124220, 46586, 125729, 68785, 77273, 142011, 50243, 64604, 123941, 138147, 125088, 138473, 77273, 133407, 63237, 136077, 85153, 126010, 73441, 39434, 123890, 20064, 73441, 124766, 33090, 125197, 73441, 13, 715, 128259, 73274, 125638, 124148, 143331, 128248, 132371, 73441, 128248, 138752, 68785, 128264, 128248, 131865, 25871, 124172, 127288, 124058, 125573, 14558, 68785, 128264, 128248, 131132, 47632, 129458, 124636, 55334, 77703, 11071, 124669, 126453, 31073, 124325, 124058, 125573, 73441, 13, 45577, 133299, 128420, 124209, 124328, 25871, 128261, 134684, 124636, 125110, 125275, 68785, 128388, 73274, 124676, 13, 130208, 137961, 27846, 124985, 124130, 25871, 125027, 91344, 73441, 77273, 123894, 124992, 68785, 39434, 137402, 127586, 11071, 124346, 132793, 77273, 126453, 5703, 124613, 47632, 123894, 65398, 128518, 68785, 37524, 126666, 124172, 127288, 128321, 124114, 14558, 124224, 77273, 124080, 39697, 123862, 47632, 126212, 137024, 37524, 124446, 123963, 124006, 68785, 37524, 123997, 127347, 93153, 124388, 31382, 127647, 20064, 124966, 142887, 126510, 68785, 37524, 57859, 125559, 23364, 129614, 124114, 124224, 126212, 141405, 68785, 37524, 132212, 143056, 53479, 125837, 73441, 124072, 127393, 73441, 68785, 134018, 123832, 47632, 27846, 131610, 128510, 129198, 130377, 13, 715, 128280, 126198, 126731, 125629, 16157, 143385, 31073, 123961, 127347, 73441, 128438, 68785, 128261, 140260, 125007, 136930, 126453, 31073, 124325, 124058, 125573, 73441, 129581, 140545, 82168, 39697, 124678, 63237, 128288, 68785, 128248, 53710, 69682, 14558, 136719, 127087, 136079, 98719, 13, 715, 128342, 130208, 137961, 125449, 39697, 124179, 137024, 140597, 55334, 73441, 130570, 14558, 127837, 37524, 137355, 127837, 128252, 125100, 138648, 25871, 128248, 127647, 20064, 124966, 142887, 126510, 128953, 128443, 13, 45577, 138023, 50243, 32790, 69682, 25871, 124172, 127288, 77273, 39434, 123890, 20064, 77273, 134259, 74315, 124223, 123860, 125013, 135640, 129745, 68785, 128660, 126502, 125229, 126420, 128098, 124209, 13325, 124072, 33090, 55334, 21360, 126196, 137024, 123961, 128559, 124325, 68785, 128261, 50243, 39697, 124675, 129353, 132450, 143826, 131801, 124072, 124363, 130142, 128252, 125100, 138648, 25871, 128248, 125637, 129152, 142887, 124863, 37524, 123993, 126751, 93153, 124388, 124421, 125011, 13, 138829, 124678, 127837, 27846, 130400, 126543, 17166, 123940, 124552, 123961, 132261, 27846, 58656, 123995, 128617, 68785, 128476, 126214, 73274, 124131, 55057, 77703, 127288, 125572, 23224, 124176, 68785, 128707, 58656, 127837, 27846, 20931, 127552, 68238, 73594, 2236, 198, 4913, 26485, 6112, 788, 330, 31382, 125510, 8532, 128967, 93153, 124388, 31382, 137024, 142887, 126510, 77273, 39434, 123890, 20064, 37524, 133877, 16157, 128248, 138752, 497, 330, 26485, 51354, 788, 4383, 135564, 20064, 497, 330, 31382, 123993, 124917, 142887, 126510, 497, 330, 31382, 127570, 47632, 497, 330, 123995, 20064, 59842, 125090, 73771, 13325, 497, 330, 31382, 134700, 124058, 125573, 73441, 7914, 330, 26485, 27251, 788, 4383, 14293, 130010, 123980, 131801, 126195, 93153, 124388, 31382, 137024, 142887, 126510, 77273, 39434, 123890, 20064, 10465, 330, 31382, 16157, 126931, 140765, 125006, 127570, 47632, 39434, 131377, 12961, 124126, 27490, 132070, 130153, 85153, 125669, 98719, 128707, 32790, 133955, 10465, 330, 31382, 134700, 124058, 125573, 73441, 39434, 125267, 124665, 135590, 125637, 32790, 133955, 37524, 124464, 14558, 91335, 10176, 125006, 124125, 124181, 138751, 14558, 10465, 330, 31382, 123993, 124917, 140597, 55334, 73441, 39434, 64604, 129080, 124476, 126992, 123904, 25871, 128248, 124172, 127288, 10465, 330, 124341, 43635, 80970, 23224, 47632, 124269, 69682, 14558, 39434, 129198, 39434, 127923, 52157, 124232, 73441, 126543, 59842, 125090, 73771, 13325, 1189, 1125, 330, 26485, 11847, 788, 330, 9896, 46979, 497, 330, 26485, 47377, 788, 61753, 2996, 3142, 788, 330, 135564, 20064, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 123995, 20064, 59842, 125090, 73771, 13325, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 127521, 124085, 27846, 124179, 126023, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 124423, 65398, 124220, 5703, 135063, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 123904, 127188, 125572, 124104, 133065, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 136961, 124478, 43635, 124394, 53479, 124811, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 31382, 134700, 124058, 125573, 73441, 497, 330, 2996, 1819, 788, 330, 23899, 14345, 5212, 2996, 3142, 788, 330, 31382, 16157, 126931, 140765, 125006, 127570, 47632, 497, 330, 2996, 1819, 788, 330, 23899, 14345, 5212, 2996, 3142, 788, 330, 31382, 127137, 128586, 143826, 125006, 138391, 497, 330, 2996, 1819, 788, 330, 23899, 14345, 5212, 2996, 3142, 788, 330, 84532, 125520, 220, 16, 19, 134340, 497, 330, 2996, 1819, 788, 330, 3087, 9207, 23439, 73594, 151645, 198]\n",
            "inputs:\n",
            "<|im_start|>system\n",
            "You are a professional NLP data parser.\n",
            "Follow the provided `Task` by the user and the `Output Scheme` to generate the `Output JSON`.\n",
            "Do not generate any introduction or conclusion.<|im_end|>\n",
            "<|im_start|>user\n",
            "# Story:\n",
            "عاد الحديث بقوة في تونس، خلال الأسابيع القليلة الماضية، عن استقلال السلطة القضائية، وعن العدل في تنفيذ قرارات المحاكم، وعن دولة القانون والمؤسسات، وعن المحاكمة العادلة، وذلك على خلفية الجدل القائم بين الهيئة العليا للانتخابات والمحكمة الإدارية، بشأن قرارات هذه الأخيرة التي ضربت بها الهيئة عرض الحائط. \n",
            " اعتقدت النخب التونسية أن الإصلاحات القانونية التي أقدمت عليها حكومات ما بعد الثورة، من خلال دستور 2014، قد باتت أمرًا محسومًا ولا مجال للتراجع عنه. فقد وضع المشرّعون، بعد نقاشات ماراثونية طويلة امتدت لنحو ثلاث سنوات، أسس المحاكمة العادلة وشروطها ومعاييرها الدولية المعروفة. غير أن تعاطي هيئة الانتخابات مع قرار المحكمة الإدارية، أعاد الوضع إلى نقطة الصفر، وأعطى الانطباع بأن البلاد تسير بخطى ثابتة إلى الخلف، بدلًا من العكس. \n",
            " قبلت المحكمة الإدارية طعون ثلاثة مرشحين للانتخابات الرئاسية، وقررت إرجاعهم إلى السباق الانتخابي، ملغية بذلك قرارات الهيئة التي أسقطتهم بدون وجه قانوني وبتعلّات واهية، كما وصف ذلك المرشحون الثلاثة، وكما نص عليه ضمنيًا قرار المحكمة. \n",
            " وفيما توقع الرأي العام في الداخل والخارج، والفاعلون السياسيون، استئناف المرشحين لمكانهم ضمن المشهد الانتخابي كمنافسين جديين للرئيس قيس سعيّد، المنتهية ولايته، بما يجعل لانتخابات السادس من أكتوبر المقبل طعمًا ومذاقًا، جاء قرار هيئة الانتخابات محبطًا للجميع، من خلال الإمعان في إقصاء المرشحين الثلاثة. \n",
            " هذا القرار كان بمثابة بصيص أمل في تحقيق وضع انتخابي جاد يضمن مبدأ تكافؤ الفرص والتنافس النزيه، وسط حالة من التوافق الضمني بين العائلات السياسية على التحشيد خلف مرشح واحد؛ لضمان إحداث التغيير الذي يتطلع إليه كثيرون، حتى أولئك الذين اصطفوا خلف انقلاب 25 يوليوتموز 2021، وكانوا من أكثر المدافعين عنه، والمبررين للممارسات والخطوات التي اتُّخذت لاحقًا، والتي يصفها خصوم الرئيس قيس سعيّد بـالاستبدادية والدكتاتورية. \n",
            " لقد اقتنع أغلب هؤلاء بأنّ التغيير ممكن، بل هو ضروري. \n",
            " قرار هيئة الانتخابات هذا تسبب في سيل عارم من الانتقادات اللاذعة، صدرت عن رجال قانون وشخصيات سياسية وأحزاب ومنظمات، وفعاليات حقوقية في الداخل والخارج. وتم وصفه بـالتعسفي والإقصائي والمنحاز لرئيس الدولة الحالي. بل اتهمت الهيئة بتحولها إلى أداة لدى السلطة التنفيذية، بما أفقدها استقلاليتها، وبالتالي مصداقيتها، ونزع عنها صفة الحياد التي عُرفت بها الهيئة منذ إنشاء أول نسخة منها في العام 2011، بمناسبة أول انتخابات تعددية حقيقية في البلاد، إبّان ثورة 14 ينايركانون الثاني 2011. \n",
            " انتظر المحيط السياسي والشعبي تراجعًا من الهيئة؛ لضمان شفافية الانتخابات ونزاهتها، لكن هذه الأخيرة أصرت على موقفها. وخرج رئيسها، فاروق بوعسكر، ليعلن مجددًا استمرار إقصاء المرشحين الثلاثة عماد الدايمي، ومنذر الزنايدي، وعبد اللطيف المكي. ووجه اتهامًا للمحكمة الإدارية بخرق الإجراءات القانونية، الشيء الذي نفته المحكمة نفيًا قاطعًا، عبر عرض وثائق تؤكد سلامة إجراءاتها وخطواتها وفقًا للقانون والمجلة الجزائية المنظمة لعمل المحكمة ومجالات تدخلها. \n",
            " وفي خطوة متقدمة من هذا الصراع الناشئ، لجأت بعض الأطراف في البلاد إلى مقاضاة هيئة الانتخابات، باعتبارها تعمّدت تجاوز السلطة، ولم تقبل بقرارات الجهة الوحيدة المحكِّمة في العملية الانتخابية، وهي المحكمة الإدارية، التي تعدّ أحكامها باتّة ونهائية، أي غير قابلة للطعن أو الإلغاء، وفق فقهاء القانون والقضاة الإداريين، مثل القاضي الإداري المعروف أحمد صواب، الذي رفع بدوره دعوى قضائية ضد الهيئة، بوصفه مواطنًا ناخبًا، وليس بصفته القضائية. \n",
            " كانت مهمة المحكمة الإدارية التي أُنشئت العام 1972 تنحصر في مجرد البتّ في دعاوى تجاوز السلطة، التي يتم رفعها لإلغاء مقررات إدارية، قبل أن يتم تعديل القوانين المنظمة لها عام 2014، باتجاه إكسابها مزيدًا من الاستقلالية، ومنحها العلوية في قراراتها، خصوصًا في النزاعات الانتخابية، بما يجعل لها الولاية على المسار الانتخابيّ. \n",
            " غير أن هيئة الانتخابات رأت خلاف ذلك تمامًا. فقد مرّغت قرارات المحكمة الإدارية في التراب، وجعلت منها هيكلًا بلا روح، معلنة احتكارها الولاية على الانتخابات ومساراتها المختلفة، من إعلان تاريخها إلى الإعلان عن نتائجها النهائية. \n",
            " تعامل هيئة الانتخابات مع قرارات المحكمة الإدارية يعيد البلاد إلى نقطة الصفر، مما أثار مخاوف حول استقلال القضاء ونزاهة العملية الانتخابية \n",
            " ورغم الجدل الذي لم ينتهِ إلى الآن بين المؤسستين، فإن النتيجة واحدة، وهي إقصاء المرشحين الثلاثة، والإبقاء على الثلاثي المعلن منذ البداية الرئيس قيس سعيّد، وزهير المغزاوي أمين عام حركة الشعب، والعياشي الزمال رئيس حركة عازمون الذي أُدخل السجن موقوفًا؛ بسبب جرائم تدليس التزكيات الشعبية، حسب اتهام السلطة له. \n",
            " ليس هذا وحسب، بل سارعت السلطة التنفيذية إلى نشر قرار الهيئة ضمن الجريدة الرسمية للجمهورية التونسية؛ لقطع الطريق أمام أي أمل في العودة إلى الوراء، كما يردد الرئيس سعيّد دائمًا. \n",
            " بل إن السلطة، مكنت هيئة الانتخابات من شحنة الحبر الانتخابي، والأكياس الآمنة، الخاصة بأوراق الاقتراع، في رسالة مضمونة الوصول، بأن أمر المرشحين الثلاثة الذين أصرت الهيئة على إسقاط ترشحهم للانتخابات الرئاسية قد حُسم بشكل لا رجعة فيه، وأن خيار هيئة الانتخابات كان سليمًا ومنطقيًا، في تقدير السلطة. \n",
            " والحقيقة، ليست هذه المرة الأولى التي يتم فيها رفض تنفيذ قرارات المحكمة الإدارية. فقد سبق لوزارة العدل أن رفضت أو تغاضت عن تنفيذ حكم المحكمة الإدارية بإبطال قرار إعفاء القضاة 49 من أصل 57 قاضيًا، الذي اتُّخذ بموجب أمر رئاسي في يونيوحزيران 2022. \n",
            " لم تعبأ وزارة العدل بوضع هؤلاء القضاة، حتى بعد دخولهم في إضراب وحشيّ عن الطعام استمرّ لعدة أيام، ولم تلتفت إلى قرار المحكمة الإدارية. بل الأدهى من ذلك، أن هؤلاء القضاة ما يزالون حتى اليوم محل ملاحقات قضائية من قبل السلطة، لاتهامهم بشنّ إضراب وتعطيل مرفق إداري عمومي بدون وجه حق. \n",
            " حتى المنظمات الاجتماعية التي تزعم دفاعها عن القانون والعدل بين المواطنين، على غرار الاتحاد العام التونسي للشغل المنظمة النقابية الأعرق في تونس، رفضت الإذعان لقرار المحكمة الإدارية الصادر قبل بضعة أسابيع، لصالح مرصد رقابة لمكافحة الفساد، الذي يتزعمه المرشح لرئاسة الجمهورية، عماد الدايمي. \n",
            " وهذا ما تعاني منه المحكمة الإدارية منذ عقود. إذ إن اللجوء إليها سهل وميسر، لكن الاحتكام إلى قراراتها وأحكامها في فضّ النزاعات، ما يزال ضعيفًا، إن لم نقل منعدمًا. وهذا ما يطرح سؤالًا جوهريًا حول أسباب ودواعي عدم تنفيذ قرارات المحكمة الإدارية، على الرغم من كل الصلاحيات التي مُنحت لها. \n",
            " في دراسة علمية قانونية نُشرت مؤخرًا حول تنفيذ أحكام وقرارات القضاء الإداري في تونس، أشار القاضي الإداري، عماد الغابري، إلى ما أسماها تفاقم ظاهرة عدم تنفيذ أحكام القضاء الإداري، حتى أصبح يُنعت بالقضاء الذي لا تُنفذ أحكامه وقراراته، وهي الجملة التي تتردد في الواقع على جميع الألسن في تونس، كترجمة عملية على هذه اللامبالاة التي تواجه بها قرارات المحكمة الإدارية.. لامبالاة تضع اليوم مستقبل القضاء الإداري على كفّ عِفريت. \n",
            " لم ينتهِ النقاش عند عدم تنفيذ قرارات المحكمة الإدارية، إنما تعدّاه ليشمل مسألة الولاية على المسار الانتخابي، وسط تمسك المحكمة بأحقيتها القانونية على هذا الأمر. لكن هيئة الانتخابات كانت قد سبقت الجميع إلى ذلك منذ البداية، من خلال إعلان ولايتها بالكامل على العملية الانتخابية. \n",
            " فهي المحددة لرزنامة الانتخابات، وهي من تقرر تاريخ يوم الاقتراع، وهي من تشرف على عملية التصويت، ومن تعلن عن نتائجه النهائية. وزادت على ذلك، بأن أعطت لنفسها حق الولاية على الإعلام والمؤسسات الإعلامية، بل حتى على المادة الإعلامية المرشحة للبثّ، وعلى ما يُقال في بعض المنابر الإعلامية، خصوصًا الانتقادات التي توجّه إلى الهيئة. \n",
            " ليس هذا وحسب، بل إن هيئة الانتخابات أعلنت ولايتها على مشاركة المنظمات المختصة في مراقبة الانتخابات، مثل منظمتَي أنا يقظ ومراقبون، واتهمتهما بالفساد المالي، بناءً على ما قالت إنها إشعارات من السلطات الرسمية بحصولهما على تمويل أجنبي. هذا يعني أن الهيئة استحوذت حتى على دور القضاء، المخول وحده بتأكيد أو نفي تهمة الفساد المالي على المنظمتين. \n",
            " هذا النزوع للهيمنة على العملية الانتخابية، واستبعاد المحكمة الإدارية من مجالات اختصاصها المنصوص عليها قانونًا في علاقة بالانتخابات، جعلا العديد من الخبراء وأساتذة القانون يخرجون عن صمتهم، ويعبّرون عن رفضهم ذلك بوضوح. \n",
            " فقد اعتبر الأستاذ كمال بن مسعود، المتخصص في القضاء الإداري، أن المحكمة الإدارية تتمتع بالولاية الكاملة على الانتخابات، خصوصًا في النزاعات الانتخابية والأحكام القضائية الباتّة الصادرة عنها، وهو ما أكده عدد من المختصين في القانون الدستوري، في بيان نُشر الأسبوع المنقضي في عدة منابر إعلامية تونسية وأجنبية. \n",
            " لا يقتصر المشكل على الولاية على الانتخابات، أو على مكانة القضاء الإداري، أو على مجالات تنفيذ قرارات المحكمة الإدارية. فتلك هي الشجرة التي تخفي الغابة، كما يقال. الأمر يتعلق بمشكلة سياسية في العمق، ترتبط بالإرادة السياسية في المحاكمات العادلة، وجعل القضاء هو الفيصل في النزاعات بين السلطة وخصومها، وتحقيق استقلال المؤسسة القضائية، وضمان مبدأ الفصل بين السلطات، وحماية الحقوق المدنية والسياسية، والحريات بجميع تمظهراتها. \n",
            " هذا ما تعكسه المعارك الحقيقية اليوم، التي يبدو أن ملف المحكمة الإدارية ليس سوى جزء من كل، على رأي المناطقة القدماء. \n",
            " إن الأمر يتعلق بنزوع السلطة التنفيذية تاريخيًا وحاضرًا إلى الهيمنة على المؤسسة القضائية بشكل عام. فمنذ نشأة القضاء في تونس في نهاية خمسينيات القرن الماضي، وهو محكوم بلعبة الشد والجذب مع السلطة الحاكمة، التي نزعت عبر التاريخ التونسي الحديث والمعاصر إلى الهيمنة على المرفق القضائي وسلبه استقلاليته. بدءًا بحكم الرئيس الراحل الحبيب بورقيبة، حيث كان يسمى قضاء الزعيم، مرورًا بفترة ح```json\n",
            "{\"story_title\": \"الجدل حول استقلال السلطة القضائية في تونس وتأثيره على الانتخابات\", \"story_keywords\": [\"تونس\", \"السلطة القضائية\", \"الانتخابات\", \"قيس سعيّد\", \"المحكمة الإدارية\"], \"story_summary\": [\"تزايد الحديث عن استقلال السلطة القضائية في تونس.\", \"الهيئة العليا للانتخابات تواجه انتقادات بسبب إقصاء مرشحين.\", \"المحكمة الإدارية تقبل طعون المرشحين وتعيدهم للسباق الانتخابي.\", \"السلطة التنفيذية تُتهم بالهيمنة على القضاء.\", \"استطلاعات الرأي تظهر تراجع شعبية الرئيس سعيّد.\"], \"story_category\": \"politics\", \"story_entities\": [{\"entity_value\": \"تونس\", \"entity_type\": \"location\"}, {\"entity_value\": \"قيس سعيّد\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"فاروق بوعسكر\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"عماد الدايمي\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"منذر الزنايدي\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"عبد اللطيف المكي\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"المحكمة الإدارية\", \"entity_type\": \"organization\"}, {\"entity_value\": \"الهيئة العليا للانتخابات\", \"entity_type\": \"organization\"}, {\"entity_value\": \"الاتحاد العام التونسي للشغل\", \"entity_type\": \"organization\"}, {\"entity_value\": \"ثورة 14 يناير\", \"entity_type\": \"event\"}]}\n",
            "```<|im_end|>\n",
            "\n",
            "label_ids:\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 73594, 2236, 198, 4913, 26485, 6112, 788, 330, 31382, 125510, 8532, 128967, 93153, 124388, 31382, 137024, 142887, 126510, 77273, 39434, 123890, 20064, 37524, 133877, 16157, 128248, 138752, 497, 330, 26485, 51354, 788, 4383, 135564, 20064, 497, 330, 31382, 123993, 124917, 142887, 126510, 497, 330, 31382, 127570, 47632, 497, 330, 123995, 20064, 59842, 125090, 73771, 13325, 497, 330, 31382, 134700, 124058, 125573, 73441, 7914, 330, 26485, 27251, 788, 4383, 14293, 130010, 123980, 131801, 126195, 93153, 124388, 31382, 137024, 142887, 126510, 77273, 39434, 123890, 20064, 10465, 330, 31382, 16157, 126931, 140765, 125006, 127570, 47632, 39434, 131377, 12961, 124126, 27490, 132070, 130153, 85153, 125669, 98719, 128707, 32790, 133955, 10465, 330, 31382, 134700, 124058, 125573, 73441, 39434, 125267, 124665, 135590, 125637, 32790, 133955, 37524, 124464, 14558, 91335, 10176, 125006, 124125, 124181, 138751, 14558, 10465, 330, 31382, 123993, 124917, 140597, 55334, 73441, 39434, 64604, 129080, 124476, 126992, 123904, 25871, 128248, 124172, 127288, 10465, 330, 124341, 43635, 80970, 23224, 47632, 124269, 69682, 14558, 39434, 129198, 39434, 127923, 52157, 124232, 73441, 126543, 59842, 125090, 73771, 13325, 1189, 1125, 330, 26485, 11847, 788, 330, 9896, 46979, 497, 330, 26485, 47377, 788, 61753, 2996, 3142, 788, 330, 135564, 20064, 497, 330, 2996, 1819, 788, 330, 2527, 14345, 5212, 2996, 3142, 788, 330, 123995, 20064, 59842, 125090, 73771, 13325, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 127521, 124085, 27846, 124179, 126023, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 124423, 65398, 124220, 5703, 135063, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 123904, 127188, 125572, 124104, 133065, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 136961, 124478, 43635, 124394, 53479, 124811, 497, 330, 2996, 1819, 788, 330, 8987, 1448, 1574, 14345, 5212, 2996, 3142, 788, 330, 31382, 134700, 124058, 125573, 73441, 497, 330, 2996, 1819, 788, 330, 23899, 14345, 5212, 2996, 3142, 788, 330, 31382, 16157, 126931, 140765, 125006, 127570, 47632, 497, 330, 2996, 1819, 788, 330, 23899, 14345, 5212, 2996, 3142, 788, 330, 31382, 127137, 128586, 143826, 125006, 138391, 497, 330, 2996, 1819, 788, 330, 23899, 14345, 5212, 2996, 3142, 788, 330, 84532, 125520, 220, 16, 19, 134340, 497, 330, 2996, 1819, 788, 330, 3087, 9207, 23439, 73594, 151645, 198]\n",
            "labels:\n",
            "```json\n",
            "{\"story_title\": \"الجدل حول استقلال السلطة القضائية في تونس وتأثيره على الانتخابات\", \"story_keywords\": [\"تونس\", \"السلطة القضائية\", \"الانتخابات\", \"قيس سعيّد\", \"المحكمة الإدارية\"], \"story_summary\": [\"تزايد الحديث عن استقلال السلطة القضائية في تونس.\", \"الهيئة العليا للانتخابات تواجه انتقادات بسبب إقصاء مرشحين.\", \"المحكمة الإدارية تقبل طعون المرشحين وتعيدهم للسباق الانتخابي.\", \"السلطة التنفيذية تُتهم بالهيمنة على القضاء.\", \"استطلاعات الرأي تظهر تراجع شعبية الرئيس سعيّد.\"], \"story_category\": \"politics\", \"story_entities\": [{\"entity_value\": \"تونس\", \"entity_type\": \"location\"}, {\"entity_value\": \"قيس سعيّد\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"فاروق بوعسكر\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"عماد الدايمي\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"منذر الزنايدي\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"عبد اللطيف المكي\", \"entity_type\": \"person-male\"}, {\"entity_value\": \"المحكمة الإدارية\", \"entity_type\": \"organization\"}, {\"entity_value\": \"الهيئة العليا للانتخابات\", \"entity_type\": \"organization\"}, {\"entity_value\": \"الاتحاد العام التونسي للشغل\", \"entity_type\": \"organization\"}, {\"entity_value\": \"ثورة 14 يناير\", \"entity_type\": \"event\"}]}\n",
            "```<|im_end|>\n",
            "\n",
            "[INFO|configuration_utils.py:765] 2025-12-08 20:38:28,995 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
            "[INFO|configuration_utils.py:839] 2025-12-08 20:38:28,996 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"dtype\": \"bfloat16\",\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"layer_types\": [\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"transformers_version\": \"4.57.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|2025-12-08 20:38:28] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.\n",
            "[WARNING|logging.py:328] 2025-12-08 20:38:29,360 >> `torch_dtype` is deprecated! Use `dtype` instead!\n",
            "model.safetensors: 100% 3.09G/3.09G [00:29<00:00, 104MB/s]\n",
            "[INFO|modeling_utils.py:1172] 2025-12-08 20:38:59,548 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/model.safetensors\n",
            "[INFO|modeling_utils.py:2341] 2025-12-08 20:38:59,555 >> Instantiating Qwen2ForCausalLM model under default dtype torch.bfloat16.\n",
            "[INFO|configuration_utils.py:986] 2025-12-08 20:38:59,557 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"use_cache\": false\n",
            "}\n",
            "\n",
            "generation_config.json: 100% 242/242 [00:00<00:00, 1.03MB/s]\n",
            "[INFO|configuration_utils.py:941] 2025-12-08 20:39:08,580 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/generation_config.json\n",
            "[INFO|configuration_utils.py:986] 2025-12-08 20:39:08,581 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": [\n",
            "    151645,\n",
            "    151643\n",
            "  ],\n",
            "  \"pad_token_id\": 151643,\n",
            "  \"repetition_penalty\": 1.1,\n",
            "  \"temperature\": 0.7,\n",
            "  \"top_k\": 20,\n",
            "  \"top_p\": 0.8\n",
            "}\n",
            "\n",
            "[INFO|dynamic_module_utils.py:423] 2025-12-08 20:39:08,818 >> Could not locate the custom_generate/generate.py inside Qwen/Qwen2.5-1.5B-Instruct.\n",
            "[INFO|2025-12-08 20:39:08] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.\n",
            "[INFO|2025-12-08 20:39:08] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.\n",
            "[INFO|2025-12-08 20:39:08] llamafactory.model.adapter:143 >> Upcasting trainable params to float32.\n",
            "[INFO|2025-12-08 20:39:08] llamafactory.model.adapter:143 >> Fine-tuning method: LoRA\n",
            "[INFO|2025-12-08 20:39:09] llamafactory.model.loader:143 >> trainable params: 4,358,144 || all params: 1,548,072,448 || trainable%: 0.2815\n",
            "[WARNING|trainer.py:906] 2025-12-08 20:39:09,096 >> The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "[INFO|trainer.py:749] 2025-12-08 20:39:09,806 >> Using auto half precision backend\n",
            "[WARNING|trainer.py:982] 2025-12-08 20:39:09,809 >> The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
            "[INFO|trainer.py:2519] 2025-12-08 20:39:10,323 >> ***** Running training *****\n",
            "[INFO|trainer.py:2520] 2025-12-08 20:39:10,323 >>   Num examples = 100\n",
            "[INFO|trainer.py:2521] 2025-12-08 20:39:10,323 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:2522] 2025-12-08 20:39:10,323 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:2525] 2025-12-08 20:39:10,323 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "[INFO|trainer.py:2526] 2025-12-08 20:39:10,323 >>   Gradient Accumulation steps = 4\n",
            "[INFO|trainer.py:2527] 2025-12-08 20:39:10,323 >>   Total optimization steps = 75\n",
            "[INFO|trainer.py:2528] 2025-12-08 20:39:10,325 >>   Number of trainable parameters = 4,358,144\n",
            "[INFO|integration_utils.py:867] 2025-12-08 20:39:10,326 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33momaryaser311\u001b[0m (\u001b[33momaryaser311-mansoura-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m setting up run ua85l9mk (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m setting up run ua85l9mk (0.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/LLaMA-Factory/wandb/run-20251208_203911-ua85l9mk\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mnewsx-finetune-llamafactory\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/omaryaser311-mansoura-university/llamafactory\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/omaryaser311-mansoura-university/llamafactory/runs/ua85l9mk\u001b[0m\n",
            "{'loss': 0.6555, 'grad_norm': 1.0951985120773315, 'learning_rate': 9.994504457428558e-05, 'epoch': 0.4}\n",
            "{'loss': 0.5936, 'grad_norm': 0.5033193826675415, 'learning_rate': 9.349531862043952e-05, 'epoch': 0.8}\n",
            " 33% 25/75 [18:22<36:40, 44.02s/it][INFO|trainer.py:4309] 2025-12-08 20:57:36,298 >> Saving model checkpoint to /content/drive/MyDrive/fine_tunning_qwenn/checkpoint-25\n",
            "[INFO|configuration_utils.py:765] 2025-12-08 20:57:36,889 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
            "[INFO|configuration_utils.py:839] 2025-12-08 20:57:36,890 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"dtype\": \"bfloat16\",\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"layer_types\": [\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"transformers_version\": \"4.57.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2421] 2025-12-08 20:57:36,981 >> chat template saved in /content/drive/MyDrive/fine_tunning_qwenn/checkpoint-25/chat_template.jinja\n",
            "[INFO|tokenization_utils_base.py:2590] 2025-12-08 20:57:36,989 >> tokenizer config file saved in /content/drive/MyDrive/fine_tunning_qwenn/checkpoint-25/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2599] 2025-12-08 20:57:36,996 >> Special tokens file saved in /content/drive/MyDrive/fine_tunning_qwenn/checkpoint-25/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2421] 2025-12-08 20:57:37,596 >> chat template saved in /content/drive/MyDrive/fine_tunning_qwenn/chat_template.jinja\n",
            "[INFO|tokenization_utils_base.py:2590] 2025-12-08 20:57:37,602 >> tokenizer config file saved in /content/drive/MyDrive/fine_tunning_qwenn/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2599] 2025-12-08 20:57:37,608 >> Special tokens file saved in /content/drive/MyDrive/fine_tunning_qwenn/special_tokens_map.json\n",
            "{'loss': 0.6113, 'grad_norm': 0.48569679260253906, 'learning_rate': 7.765655770625997e-05, 'epoch': 1.2}\n",
            "{'loss': 0.5276, 'grad_norm': 0.5519216656684875, 'learning_rate': 5.584776609860414e-05, 'epoch': 1.6}\n",
            "{'loss': 0.6239, 'grad_norm': 0.6430231332778931, 'learning_rate': 3.277665748578336e-05, 'epoch': 2.0}\n",
            " 67% 50/75 [36:48<20:01, 48.07s/it][INFO|trainer.py:4643] 2025-12-08 21:16:02,529 >> \n",
            "***** Running Evaluation *****\n",
            "[INFO|trainer.py:4645] 2025-12-08 21:16:02,529 >>   Num examples = 66\n",
            "[INFO|trainer.py:4648] 2025-12-08 21:16:02,529 >>   Batch size = 1\n",
            "\n",
            "  0% 0/66 [00:00<?, ?it/s]\u001b[A\n",
            "  3% 2/66 [00:05<03:10,  2.98s/it]\u001b[A\n",
            "  5% 3/66 [00:08<02:59,  2.85s/it]\u001b[A\n",
            "  6% 4/66 [00:10<02:38,  2.56s/it]\u001b[A\n",
            "  8% 5/66 [00:15<03:26,  3.38s/it]\u001b[A\n",
            "  9% 6/66 [00:21<04:14,  4.24s/it]\u001b[A\n",
            " 11% 7/66 [00:24<03:36,  3.68s/it]\u001b[A\n",
            " 12% 8/66 [00:29<04:01,  4.17s/it]\u001b[A\n",
            " 14% 9/66 [00:33<03:58,  4.18s/it]\u001b[A\n",
            " 15% 10/66 [00:36<03:35,  3.86s/it]\u001b[A\n",
            " 17% 11/66 [00:37<02:48,  3.07s/it]\u001b[A\n",
            " 18% 12/66 [00:42<03:18,  3.67s/it]\u001b[A\n",
            " 20% 13/66 [00:44<02:44,  3.10s/it]\u001b[A\n",
            " 21% 14/66 [00:47<02:31,  2.91s/it]\u001b[A\n",
            " 23% 15/66 [00:50<02:29,  2.94s/it]\u001b[A\n",
            " 24% 16/66 [00:52<02:10,  2.61s/it]\u001b[A\n",
            " 26% 17/66 [00:54<02:10,  2.67s/it]\u001b[A\n",
            " 27% 18/66 [00:57<02:09,  2.71s/it]\u001b[A\n",
            " 29% 19/66 [00:59<02:00,  2.57s/it]\u001b[A\n",
            " 30% 20/66 [01:02<01:55,  2.51s/it]\u001b[A\n",
            " 32% 21/66 [01:04<01:55,  2.56s/it]\u001b[A\n",
            " 33% 22/66 [01:09<02:20,  3.20s/it]\u001b[A\n",
            " 35% 23/66 [01:11<02:05,  2.92s/it]\u001b[A\n",
            " 36% 24/66 [01:14<01:54,  2.72s/it]\u001b[A\n",
            " 38% 25/66 [01:16<01:44,  2.56s/it]\u001b[A\n",
            " 39% 26/66 [01:18<01:37,  2.44s/it]\u001b[A\n",
            " 41% 27/66 [01:20<01:30,  2.33s/it]\u001b[A\n",
            " 42% 28/66 [01:26<02:10,  3.43s/it]\u001b[A\n",
            " 44% 29/66 [01:32<02:34,  4.19s/it]\u001b[A\n",
            " 45% 30/66 [01:33<01:58,  3.28s/it]\u001b[A\n",
            " 47% 31/66 [01:36<01:50,  3.16s/it]\u001b[A\n",
            " 48% 32/66 [01:38<01:32,  2.71s/it]\u001b[A\n",
            " 50% 33/66 [01:41<01:33,  2.83s/it]\u001b[A\n",
            " 52% 34/66 [01:43<01:23,  2.60s/it]\u001b[A\n",
            " 53% 35/66 [01:47<01:33,  3.01s/it]\u001b[A\n",
            " 55% 36/66 [01:50<01:29,  2.97s/it]\u001b[A\n",
            " 56% 37/66 [01:54<01:40,  3.45s/it]\u001b[A\n",
            " 58% 38/66 [01:58<01:41,  3.63s/it]\u001b[A\n",
            " 59% 39/66 [02:03<01:41,  3.77s/it]\u001b[A\n",
            " 61% 40/66 [02:05<01:24,  3.26s/it]\u001b[A\n",
            " 62% 41/66 [02:07<01:16,  3.06s/it]\u001b[A\n",
            " 64% 42/66 [02:09<01:06,  2.79s/it]\u001b[A\n",
            " 65% 43/66 [02:13<01:12,  3.17s/it]\u001b[A\n",
            " 67% 44/66 [02:16<01:08,  3.13s/it]\u001b[A\n",
            " 68% 45/66 [02:19<01:04,  3.06s/it]\u001b[A\n",
            " 70% 46/66 [02:25<01:18,  3.93s/it]\u001b[A\n",
            " 71% 47/66 [02:29<01:16,  4.01s/it]\u001b[A\n",
            " 73% 48/66 [02:31<00:59,  3.33s/it]\u001b[A\n",
            " 74% 49/66 [02:33<00:49,  2.92s/it]\u001b[A\n",
            " 76% 50/66 [02:35<00:40,  2.54s/it]\u001b[A\n",
            " 77% 51/66 [02:37<00:37,  2.49s/it]\u001b[A\n",
            " 79% 52/66 [02:40<00:36,  2.62s/it]\u001b[A\n",
            " 80% 53/66 [02:46<00:45,  3.47s/it]\u001b[A\n",
            " 82% 54/66 [02:49<00:40,  3.37s/it]\u001b[A\n",
            " 83% 55/66 [02:53<00:39,  3.58s/it]\u001b[A\n",
            " 85% 56/66 [02:57<00:37,  3.73s/it]\u001b[A\n",
            " 86% 57/66 [03:03<00:39,  4.40s/it]\u001b[A\n",
            " 88% 58/66 [03:04<00:28,  3.54s/it]\u001b[A\n",
            " 89% 59/66 [03:06<00:21,  3.07s/it]\u001b[A\n",
            " 91% 60/66 [03:08<00:16,  2.79s/it]\u001b[A\n",
            " 92% 61/66 [03:11<00:13,  2.67s/it]\u001b[A\n",
            " 94% 62/66 [03:17<00:14,  3.66s/it]\u001b[A\n",
            " 95% 63/66 [03:20<00:10,  3.40s/it]\u001b[A\n",
            " 97% 64/66 [03:22<00:06,  3.12s/it]\u001b[A\n",
            " 98% 65/66 [03:25<00:03,  3.06s/it]\u001b[A\n",
            "                                   \n",
            "\u001b[A{'eval_loss': 0.4620213806629181, 'eval_runtime': 214.9487, 'eval_samples_per_second': 0.307, 'eval_steps_per_second': 0.307, 'epoch': 2.0}\n",
            " 67% 50/75 [40:23<20:01, 48.07s/it]\n",
            "100% 66/66 [03:28<00:00,  3.18s/it]\u001b[A\n",
            "                                   \u001b[A[INFO|trainer.py:4309] 2025-12-08 21:19:37,496 >> Saving model checkpoint to /content/drive/MyDrive/fine_tunning_qwenn/checkpoint-50\n",
            "[INFO|configuration_utils.py:765] 2025-12-08 21:19:38,121 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
            "[INFO|configuration_utils.py:839] 2025-12-08 21:19:38,122 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"dtype\": \"bfloat16\",\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"layer_types\": [\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"transformers_version\": \"4.57.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2421] 2025-12-08 21:19:38,217 >> chat template saved in /content/drive/MyDrive/fine_tunning_qwenn/checkpoint-50/chat_template.jinja\n",
            "[INFO|tokenization_utils_base.py:2590] 2025-12-08 21:19:38,233 >> tokenizer config file saved in /content/drive/MyDrive/fine_tunning_qwenn/checkpoint-50/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2599] 2025-12-08 21:19:38,240 >> Special tokens file saved in /content/drive/MyDrive/fine_tunning_qwenn/checkpoint-50/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2421] 2025-12-08 21:19:38,820 >> chat template saved in /content/drive/MyDrive/fine_tunning_qwenn/chat_template.jinja\n",
            "[INFO|tokenization_utils_base.py:2590] 2025-12-08 21:19:39,115 >> tokenizer config file saved in /content/drive/MyDrive/fine_tunning_qwenn/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2599] 2025-12-08 21:19:39,122 >> Special tokens file saved in /content/drive/MyDrive/fine_tunning_qwenn/special_tokens_map.json\n",
            "{'loss': 0.4915, 'grad_norm': 0.6001511216163635, 'learning_rate': 1.3423433236816563e-05, 'epoch': 2.4}\n",
            "{'loss': 0.6023, 'grad_norm': 0.5748378038406372, 'learning_rate': 1.9657406211579966e-06, 'epoch': 2.8}\n",
            "100% 75/75 [58:51<00:00, 46.04s/it][INFO|trainer.py:4309] 2025-12-08 21:38:04,710 >> Saving model checkpoint to /content/drive/MyDrive/fine_tunning_qwenn/checkpoint-75\n",
            "[INFO|configuration_utils.py:765] 2025-12-08 21:38:05,305 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
            "[INFO|configuration_utils.py:839] 2025-12-08 21:38:05,306 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"dtype\": \"bfloat16\",\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"layer_types\": [\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"transformers_version\": \"4.57.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2421] 2025-12-08 21:38:05,398 >> chat template saved in /content/drive/MyDrive/fine_tunning_qwenn/checkpoint-75/chat_template.jinja\n",
            "[INFO|tokenization_utils_base.py:2590] 2025-12-08 21:38:05,404 >> tokenizer config file saved in /content/drive/MyDrive/fine_tunning_qwenn/checkpoint-75/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2599] 2025-12-08 21:38:05,410 >> Special tokens file saved in /content/drive/MyDrive/fine_tunning_qwenn/checkpoint-75/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2421] 2025-12-08 21:38:05,936 >> chat template saved in /content/drive/MyDrive/fine_tunning_qwenn/chat_template.jinja\n",
            "[INFO|tokenization_utils_base.py:2590] 2025-12-08 21:38:05,942 >> tokenizer config file saved in /content/drive/MyDrive/fine_tunning_qwenn/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2599] 2025-12-08 21:38:05,949 >> Special tokens file saved in /content/drive/MyDrive/fine_tunning_qwenn/special_tokens_map.json\n",
            "[INFO|trainer.py:2810] 2025-12-08 21:38:06,187 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 3535.8623, 'train_samples_per_second': 0.085, 'train_steps_per_second': 0.021, 'train_loss': 0.5811677487691244, 'epoch': 3.0}\n",
            "100% 75/75 [58:53<00:00, 47.11s/it]\n",
            "[INFO|trainer.py:5114] 2025-12-08 21:38:06,549 >> Waiting for the current checkpoint push to be finished, this might take a couple of minutes.\n",
            "[INFO|trainer.py:4309] 2025-12-08 21:38:23,656 >> Saving model checkpoint to /content/drive/MyDrive/fine_tunning_qwenn\n",
            "[INFO|configuration_utils.py:765] 2025-12-08 21:38:24,184 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
            "[INFO|configuration_utils.py:839] 2025-12-08 21:38:24,185 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"dtype\": \"bfloat16\",\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"layer_types\": [\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"transformers_version\": \"4.57.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2421] 2025-12-08 21:38:24,279 >> chat template saved in /content/drive/MyDrive/fine_tunning_qwenn/chat_template.jinja\n",
            "[INFO|tokenization_utils_base.py:2590] 2025-12-08 21:38:24,285 >> tokenizer config file saved in /content/drive/MyDrive/fine_tunning_qwenn/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2599] 2025-12-08 21:38:24,291 >> Special tokens file saved in /content/drive/MyDrive/fine_tunning_qwenn/special_tokens_map.json\n",
            "[INFO|trainer.py:4309] 2025-12-08 21:38:24,516 >> Saving model checkpoint to /content/drive/MyDrive/fine_tunning_qwenn\n",
            "[INFO|configuration_utils.py:765] 2025-12-08 21:38:25,119 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
            "[INFO|configuration_utils.py:839] 2025-12-08 21:38:25,121 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"dtype\": \"bfloat16\",\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"layer_types\": [\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"transformers_version\": \"4.57.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2421] 2025-12-08 21:38:25,221 >> chat template saved in /content/drive/MyDrive/fine_tunning_qwenn/chat_template.jinja\n",
            "[INFO|tokenization_utils_base.py:2590] 2025-12-08 21:38:25,227 >> tokenizer config file saved in /content/drive/MyDrive/fine_tunning_qwenn/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2599] 2025-12-08 21:38:25,231 >> Special tokens file saved in /content/drive/MyDrive/fine_tunning_qwenn/special_tokens_map.json\n",
            "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            \n",
            "New Data Upload               : |          |  0.00B /  0.00B            \u001b[A\n",
            "\n",
            "  ...ning_qwenn/val_ds/val.rar: 100% 131k/131k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...g_qwenn/training_args.bin: 100% 6.29k/6.29k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...ning_qwenn/tokenizer.json:  73% 8.30M/11.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ..._qwenn/train_ds/train.rar: 100% 5.55M/5.55M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...adapter_model.safetensors:  48% 8.33M/17.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "  ...ning_qwenn/val_ds/val.rar: 100% 131k/131k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...g_qwenn/training_args.bin: 100% 6.29k/6.29k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...ning_qwenn/tokenizer.json:  73% 8.30M/11.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ..._qwenn/train_ds/train.rar: 100% 5.55M/5.55M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (3 / 5)      :  65% 22.3M/34.6M [00:00<00:00, 84.2MB/s,   ???B/s  ]\n",
            "\n",
            "  ...ning_qwenn/val_ds/val.rar: 100% 131k/131k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...g_qwenn/training_args.bin: 100% 6.29k/6.29k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...ning_qwenn/tokenizer.json: 100% 11.4M/11.4M [00:00<00:00, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ..._qwenn/train_ds/train.rar: 100% 5.55M/5.55M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 5)      : 100% 34.6M/34.6M [00:00<00:00, 83.3MB/s, 61.4MB/s  ]\n",
            "\n",
            "  ...ning_qwenn/val_ds/val.rar: 100% 131k/131k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...g_qwenn/training_args.bin: 100% 6.29k/6.29k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...ning_qwenn/tokenizer.json: 100% 11.4M/11.4M [00:00<00:00, 8.02MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ..._qwenn/train_ds/train.rar: 100% 5.55M/5.55M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...adapter_model.safetensors: 100% 17.4M/17.4M [00:00<00:00, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "  ...ning_qwenn/val_ds/val.rar: 100% 131k/131k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...g_qwenn/training_args.bin: 100% 6.29k/6.29k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...ning_qwenn/tokenizer.json: 100% 11.4M/11.4M [00:00<00:00, 5.94MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ..._qwenn/train_ds/train.rar: 100% 5.55M/5.55M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...adapter_model.safetensors: 100% 17.4M/17.4M [00:00<00:00, 17.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "  ...ning_qwenn/val_ds/val.rar: 100% 131k/131k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...g_qwenn/training_args.bin: 100% 6.29k/6.29k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...ning_qwenn/tokenizer.json: 100% 11.4M/11.4M [00:00<00:00, 5.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ..._qwenn/train_ds/train.rar: 100% 5.55M/5.55M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 5)      : 100% 34.6M/34.6M [00:00<00:00, 42.7MB/s, 20.4MB/s  ]\n",
            "New Data Upload               : |          |  0.00B /  0.00B,  0.00B/s  \n",
            "  ...ning_qwenn/val_ds/val.rar: 100% 131k/131k [00:00<?, ?B/s]\n",
            "  ...g_qwenn/training_args.bin: 100% 6.29k/6.29k [00:00<?, ?B/s]\n",
            "  ...ning_qwenn/tokenizer.json: 100% 11.4M/11.4M [00:00<00:00, 5.27MB/s]\n",
            "  ..._qwenn/train_ds/train.rar: 100% 5.55M/5.55M [00:00<?, ?B/s]\n",
            "  ...adapter_model.safetensors: 100% 17.4M/17.4M [00:00<00:00, 15.7MB/s]\n",
            "***** train metrics *****\n",
            "  epoch                    =        3.0\n",
            "  total_flos               =  4921652GF\n",
            "  train_loss               =     0.5812\n",
            "  train_runtime            = 0:58:55.86\n",
            "  train_samples_per_second =      0.085\n",
            "  train_steps_per_second   =      0.021\n",
            "Figure saved at: /content/drive/MyDrive/fine_tunning_qwenn/training_loss.png\n",
            "Figure saved at: /content/drive/MyDrive/fine_tunning_qwenn/training_eval_loss.png\n",
            "[WARNING|2025-12-08 21:38:31] llamafactory.extras.ploting:148 >> No metric eval_accuracy to plot.\n",
            "[INFO|trainer.py:4643] 2025-12-08 21:38:31,326 >> \n",
            "***** Running Evaluation *****\n",
            "[INFO|trainer.py:4645] 2025-12-08 21:38:31,327 >>   Num examples = 66\n",
            "[INFO|trainer.py:4648] 2025-12-08 21:38:31,327 >>   Batch size = 1\n",
            "100% 66/66 [03:29<00:00,  3.18s/it]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        3.0\n",
            "  eval_loss               =     0.4591\n",
            "  eval_runtime            = 0:03:35.67\n",
            "  eval_samples_per_second =      0.306\n",
            "  eval_steps_per_second   =      0.306\n",
            "[INFO|trainer.py:4309] 2025-12-08 21:42:07,018 >> Saving model checkpoint to /content/drive/MyDrive/fine_tunning_qwenn\n",
            "[INFO|configuration_utils.py:765] 2025-12-08 21:42:07,553 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\n",
            "[INFO|configuration_utils.py:839] 2025-12-08 21:42:07,554 >> Model config Qwen2Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"dtype\": \"bfloat16\",\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"layer_types\": [\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\",\n",
            "    \"full_attention\"\n",
            "  ],\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"transformers_version\": \"4.57.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2421] 2025-12-08 21:42:07,648 >> chat template saved in /content/drive/MyDrive/fine_tunning_qwenn/chat_template.jinja\n",
            "[INFO|tokenization_utils_base.py:2590] 2025-12-08 21:42:07,655 >> tokenizer config file saved in /content/drive/MyDrive/fine_tunning_qwenn/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2599] 2025-12-08 21:42:07,661 >> Special tokens file saved in /content/drive/MyDrive/fine_tunning_qwenn/special_tokens_map.json\n",
            "[INFO|modelcard.py:456] 2025-12-08 21:42:08,218 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n",
            "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            \n",
            "New Data Upload               : |          |  0.00B /  0.00B            \u001b[A\n",
            "\n",
            "  ...ning_qwenn/val_ds/val.rar: 100% 131k/131k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...g_qwenn/training_args.bin: 100% 6.29k/6.29k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...adapter_model.safetensors:  96% 16.8M/17.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ..._qwenn/train_ds/train.rar: 100% 5.55M/5.55M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...ning_qwenn/tokenizer.json: 100% 11.4M/11.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "  ...ning_qwenn/val_ds/val.rar: 100% 131k/131k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...g_qwenn/training_args.bin: 100% 6.29k/6.29k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...adapter_model.safetensors:  96% 16.8M/17.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ..._qwenn/train_ds/train.rar: 100% 5.55M/5.55M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (4 / 5)      :  98% 33.9M/34.6M [00:00<00:00, 156MB/s,   ???B/s  ]\n",
            "\n",
            "  ...ning_qwenn/val_ds/val.rar: 100% 131k/131k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...g_qwenn/training_args.bin: 100% 6.29k/6.29k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...adapter_model.safetensors: 100% 17.4M/17.4M [00:00<00:00, 3.52MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ..._qwenn/train_ds/train.rar: 100% 5.55M/5.55M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 5)      : 100% 34.6M/34.6M [00:00<00:00, 71.4MB/s, 3.48MB/s  ]\n",
            "\n",
            "  ...ning_qwenn/val_ds/val.rar: 100% 131k/131k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...g_qwenn/training_args.bin: 100% 6.29k/6.29k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...adapter_model.safetensors: 100% 17.4M/17.4M [00:00<00:00, 1.75MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ..._qwenn/train_ds/train.rar: 100% 5.55M/5.55M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...ning_qwenn/tokenizer.json: 100% 11.4M/11.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "  ...ning_qwenn/val_ds/val.rar: 100% 131k/131k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...g_qwenn/training_args.bin: 100% 6.29k/6.29k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...adapter_model.safetensors: 100% 17.4M/17.4M [00:00<00:00, 1.17MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ..._qwenn/train_ds/train.rar: 100% 5.55M/5.55M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...ning_qwenn/tokenizer.json: 100% 11.4M/11.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "  ...ning_qwenn/val_ds/val.rar: 100% 131k/131k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...g_qwenn/training_args.bin: 100% 6.29k/6.29k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...adapter_model.safetensors: 100% 17.4M/17.4M [00:00<00:00, 874kB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ..._qwenn/train_ds/train.rar: 100% 5.55M/5.55M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...ning_qwenn/tokenizer.json: 100% 11.4M/11.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "  ...ning_qwenn/val_ds/val.rar: 100% 131k/131k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...g_qwenn/training_args.bin: 100% 6.29k/6.29k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...adapter_model.safetensors: 100% 17.4M/17.4M [00:00<00:00, 729kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ..._qwenn/train_ds/train.rar: 100% 5.55M/5.55M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ...ning_qwenn/tokenizer.json: 100% 11.4M/11.4M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "  ...ning_qwenn/val_ds/val.rar: 100% 131k/131k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "  ...g_qwenn/training_args.bin: 100% 6.29k/6.29k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "  ...adapter_model.safetensors: 100% 17.4M/17.4M [00:00<00:00, 699kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  ..._qwenn/train_ds/train.rar: 100% 5.55M/5.55M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Processing Files (5 / 5)      : 100% 34.6M/34.6M [00:01<00:00, 28.6MB/s,  698kB/s  ]\n",
            "New Data Upload               : |          |  0.00B /  0.00B,  0.00B/s  \n",
            "  ...ning_qwenn/val_ds/val.rar: 100% 131k/131k [00:01<?, ?B/s]\n",
            "  ...g_qwenn/training_args.bin: 100% 6.29k/6.29k [00:01<?, ?B/s]\n",
            "  ...adapter_model.safetensors: 100% 17.4M/17.4M [00:01<00:00, 695kB/s]\n",
            "  ..._qwenn/train_ds/train.rar: 100% 5.55M/5.55M [00:01<?, ?B/s]\n",
            "  ...ning_qwenn/tokenizer.json: 100% 11.4M/11.4M [00:01<?, ?B/s]\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mnewsx-finetune-llamafactory\u001b[0m at: \u001b[34m\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20251208_203911-ua85l9mk/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!cd LLaMA-Factory/ && llamafactory-cli train /content/LLaMA-Factory/examples/train_lora/news_finetune.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7xz52iiY0E3T",
      "metadata": {
        "id": "7xz52iiY0E3T"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "y4sHjhbS0FCh",
      "metadata": {
        "id": "y4sHjhbS0FCh"
      },
      "source": [
        "## Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UcABnEqcow5_",
      "metadata": {
        "id": "UcABnEqcow5_"
      },
      "outputs": [],
      "source": [
        "ft_model_id = \"/content/drive/MyDrive/fine_tunning_qwenn\"\n",
        "model.load_adapter(ft_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FgPbQKw76j1h",
      "metadata": {
        "id": "FgPbQKw76j1h"
      },
      "outputs": [],
      "source": [
        "story = '''\n",
        "تواصل أسواق الدواجن بالدقهلية عرض كميات متنوعة من الدواجن والطيور، في ظل استقرار حركة البيع والشراء خلال ساعات النهار.\n",
        "\n",
        "ويظهر اهتمام واضح من المواطنين بمتابعة الأسعار اليومية، خاصة لكون الدواجن من السلع الأساسية داخل كل منزل، وتُعد من أكثر الخيارات التي يعتمد عليها الأهالي في وجباتهم اليومية. وتستقبل الأسواق كميات مناسبة من المزارع، ما يسهم في توفير الأصناف المطلوبة بمختلف أنواعها.\n",
        "\n",
        "وتشهد الأسواق حركة معتدلة منذ بداية اليوم، مع استمرار توافد الأهالي لاختيار المنتجات المناسبة لهم. ويعتمد الكثير من المواطنين على متابعة حركة السوق اليومية، خصوصًا أن الدواجن تعد من أكثر السلع اعتمادًا داخل الوجبات المنزلية، نظرًا لتنوع طرق طهيها وسهولة تجهيزها.\n",
        "لذا يفضل البعض متابعة الأسعار أولًا عبر المنصات الإخبارية قبل اتخاذ قرار الشراء.\n",
        "\n",
        "أسعار الدواجن\n",
        "رصدت الدستور الاسعار بالاسواق كالاتي: سجل سعر الدواجن البيضاء من 75 إلى 80 جنيهًا للكيلو، بينما بلغت الساسو 90 إلى 95 جنيهًا، والدواجن البلدي تراوحت بين 100 و115 جنيهًا للكيلو، أما الدواجن الأمهات فاستقرت أسعارها ما بين 65 إلى 70 جنيهًا، وسعر البط البلدي بلغ حوالي 120 جنيهًا للكيلو، والرومي من 140 حتى 160 جنيهًا.\n",
        "\n",
        "وتراوحت أسعار البط كالآتي: البط البلدي: 140 جنيهًا للكيلو، البط الفرنسي: 90 جنيهًا للكيلو، البط المسكوفي: 120 جنيهًا للكيلو، البط البكيني: 100 جنيه للكيلو.\n",
        "\n",
        "وسجلت أسعار الكتاكيت: الكتاكيت البيضاء: 45 - 60 جنيهًا للكتكوت، الكتاكيت الساسو: 30 - 40 جنيهًا للكتكوت.\n",
        "\n",
        "بلغ سعر البانيه المجمد من 170 إلى 190 جنيهًا للكيلو، وشيش طاووق من 160 إلى 180 جنيهًا، والدبابيس من 110 إلى 130 جنيهًا، فيما تراوحت أسعار الأجنحة بين 70 و85 جنيهًا، والهياكل من 35 إلى 40 جنيهًا، والكبد والقوانص من 70 إلى 85 جنيهًا.\n",
        "\n",
        "ذكرت منى عبد الهادي، ربة منزل من المنصورة، أنها تتابع أسعار الدواجن يوميًا لأنها جزء أساسي من وجبات أسرتها، مؤكدة أن توفر الأنواع المختلفة يساعدها في اختيار ما يناسب احتياجاتها الأسبوعية.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G6g3sTvf6uBJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6g3sTvf6uBJ",
        "outputId": "a6dd4a0a-ac18-4c0d-e352-808eb63fbefb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': 'You are an NLP data paraser.\\nYou will be provided by an Arabic text associated with a Pydantic scheme.\\nGenerate the ouptut in the same story language.\\nYou have to extract JSON details from text according the Pydantic details.\\nExtract details as mentioned in text.\\nDo not generate any introduction or conclusion.'},\n",
              " {'role': 'user',\n",
              "  'content': '## Story:\\nتواصل أسواق الدواجن بالدقهلية عرض كميات متنوعة من الدواجن والطيور، في ظل استقرار حركة البيع والشراء خلال ساعات النهار.\\n\\nويظهر اهتمام واضح من المواطنين بمتابعة الأسعار اليومية، خاصة لكون الدواجن من السلع الأساسية داخل كل منزل، وتُعد من أكثر الخيارات التي يعتمد عليها الأهالي في وجباتهم اليومية. وتستقبل الأسواق كميات مناسبة من المزارع، ما يسهم في توفير الأصناف المطلوبة بمختلف أنواعها.\\n\\nوتشهد الأسواق حركة معتدلة منذ بداية اليوم، مع استمرار توافد الأهالي لاختيار المنتجات المناسبة لهم. ويعتمد الكثير من المواطنين على متابعة حركة السوق اليومية، خصوصًا أن الدواجن تعد من أكثر السلع اعتمادًا داخل الوجبات المنزلية، نظرًا لتنوع طرق طهيها وسهولة تجهيزها.\\nلذا يفضل البعض متابعة الأسعار أولًا عبر المنصات الإخبارية قبل اتخاذ قرار الشراء.\\n\\nأسعار الدواجن\\nرصدت الدستور الاسعار بالاسواق كالاتي: سجل سعر الدواجن البيضاء من 75 إلى 80 جنيهًا للكيلو، بينما بلغت الساسو 90 إلى 95 جنيهًا، والدواجن البلدي تراوحت بين 100 و115 جنيهًا للكيلو، أما الدواجن الأمهات فاستقرت أسعارها ما بين 65 إلى 70 جنيهًا، وسعر البط البلدي بلغ حوالي 120 جنيهًا للكيلو، والرومي من 140 حتى 160 جنيهًا.\\n\\nوتراوحت أسعار البط كالآتي: البط البلدي: 140 جنيهًا للكيلو، البط الفرنسي: 90 جنيهًا للكيلو، البط المسكوفي: 120 جنيهًا للكيلو، البط البكيني: 100 جنيه للكيلو.\\n\\nوسجلت أسعار الكتاكيت: الكتاكيت البيضاء: 45 - 60 جنيهًا للكتكوت، الكتاكيت الساسو: 30 - 40 جنيهًا للكتكوت.\\n\\nبلغ سعر البانيه المجمد من 170 إلى 190 جنيهًا للكيلو، وشيش طاووق من 160 إلى 180 جنيهًا، والدبابيس من 110 إلى 130 جنيهًا، فيما تراوحت أسعار الأجنحة بين 70 و85 جنيهًا، والهياكل من 35 إلى 40 جنيهًا، والكبد والقوانص من 70 إلى 85 جنيهًا.\\n\\nذكرت منى عبد الهادي، ربة منزل من المنصورة، أنها تتابع أسعار الدواجن يوميًا لأنها جزء أساسي من وجبات أسرتها، مؤكدة أن توفر الأنواع المختلفة يساعدها في اختيار ما يناسب احتياجاتها الأسبوعية.\\n\\n## Pydantic Details:\\nSTRICT OUTPUT FORMAT:\\n- Return only the JSON value that conforms to the schema. Do not include any additional text, explanations, headings, or separators.\\n- Do not wrap the JSON in Markdown or code fences (no ``` or ```json).\\n- Do not prepend or append any text (e.g., do not write \"Here is the JSON:\").\\n- The response must be a single top-level JSON value exactly as required by the schema (object/array/etc.), with no trailing commas or comments.\\n\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]} the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema (shown in a code block for readability only — do not include any backticks or Markdown in your output):\\n```\\n{\"$defs\": {\"Entity\": {\"properties\": {\"entity_value\": {\"description\": \"The actual name or value of the entity.\", \"title\": \"Entity Value\", \"type\": \"string\"}, \"entity_type\": {\"description\": \"The type of recognized entity.\", \"enum\": [\"person-male\", \"person-female\", \"location\", \"organization\", \"event\", \"time\", \"quantity\", \"money\", \"product\", \"law\", \"disease\", \"artifact\", \"not_specified\"], \"title\": \"Entity Type\", \"type\": \"string\"}}, \"required\": [\"entity_value\", \"entity_type\"], \"title\": \"Entity\", \"type\": \"object\"}}, \"properties\": {\"story_title\": {\"description\": \"a sutiable title for the story\", \"maxLength\": 250, \"minLength\": 15, \"title\": \"Story Title\", \"type\": \"string\"}, \"story_keywords\": {\"description\": \"Relevant keywords associated with the story\", \"items\": {\"type\": \"string\"}, \"minItems\": 20, \"title\": \"Story Keywords\", \"type\": \"array\"}, \"story_summery\": {\"description\": \"Summarized key points about the story (1-5 points).\", \"items\": {\"type\": \"string\"}, \"maxItems\": 5, \"minItems\": 1, \"title\": \"Story Summery\", \"type\": \"array\"}, \"story_category\": {\"description\": \"Category of the news story.\", \"enum\": [\"politics\", \"sports\", \"art\", \"technology\", \"economy\", \"health\", \"entertainment\", \"science\", \"not_specified\"], \"title\": \"Story Category\", \"type\": \"string\"}, \"story_entites\": {\"description\": \"List of identified entities in the story.\", \"items\": {\"$ref\": \"#/$defs/Entity\"}, \"maxItems\": 10, \"minItems\": 1, \"title\": \"Story Entites\", \"type\": \"array\"}}, \"required\": [\"story_title\", \"story_keywords\", \"story_summery\", \"story_category\", \"story_entites\"]}\\n```\\n\\n## Story Details:\\n```json'}]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "details_extraction_messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\\n\".join([\n",
        "            \"You are an NLP data paraser.\",\n",
        "            \"You will be provided by an Arabic text associated with a Pydantic scheme.\",\n",
        "            \"Generate the ouptut in the same story language.\",\n",
        "            \"You have to extract JSON details from text according the Pydantic details.\",\n",
        "            \"Extract details as mentioned in text.\",\n",
        "            \"Do not generate any introduction or conclusion.\"\n",
        "        ])\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\\n\".join([\n",
        "            \"## Story:\",\n",
        "            story.strip(),\n",
        "            \"\",\n",
        "\n",
        "            \"## Pydantic Details:\",\n",
        "            format_instructions ,\n",
        "            \"\",\n",
        "\n",
        "            \"## Story Details:\",\n",
        "            \"```json\"\n",
        "        ])\n",
        "    }\n",
        "]\n",
        "details_extraction_messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lSGcQU184DMb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSGcQU184DMb",
        "outputId": "47a51fb2-a409-4582-c6b1-57be229e2c55"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        }
      ],
      "source": [
        "def generate_responce(TEXT : list):\n",
        "  text = tokenizer.apply_chat_template(\n",
        "      TEXT ,\n",
        "      tokenize=False,\n",
        "      add_generation_prompt=True\n",
        "  )\n",
        "\n",
        "  model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "\n",
        "  generated_ids = model.generate(\n",
        "      model_inputs.input_ids ,\n",
        "      max_new_tokens=1024,\n",
        "      do_sample=False, top_k=None, temperature=None, top_p=None,\n",
        "  )\n",
        "\n",
        "  generated_ids = [\n",
        "        output_ids[len(input_ids):]\n",
        "        for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "    ]\n",
        "\n",
        "  response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "  return response\n",
        "\n",
        "response = generate_responce(details_extraction_messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lxeMvCPI6D8P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxeMvCPI6D8P",
        "outputId": "15734660-a3c5-4d76-b260-f388ee38d261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "{\n",
            "  \"story_title\": \"أسعار الدواجن بالدقهلية\",\n",
            "  \"story_keywords\": [\n",
            "    \"أسعار الدواجن\",\n",
            "    \"الدقهلية\",\n",
            "    \"البيع والشراء\",\n",
            "    \"الدجاج\",\n",
            "    \"البط\",\n",
            "    \"الرومي\",\n",
            "    \"البانيه المجمد\",\n",
            "    \"الشيش الطاووق\",\n",
            "    \"الدبابيس\",\n",
            "    \"الأجنحة\",\n",
            "    \"الكبد والقوانص\"\n",
            "  ],\n",
            "  \"story_summery\": [\n",
            "    \"تواصل أسواق الدواجن بالدقهلية عرض كميات متنوعة من الدواجن والطيور.\",\n",
            "    \"في ظل استقرار حركة البيع والشراء خلال ساعات النهار.\",\n",
            "    \"يظهر اهتمام واضح من المواطنين بمتابعة الأسعار اليومية.\",\n",
            "    \"الدواجن تعد من السلع الأساسية داخل كل منزل.\",\n",
            "    \"تُعد من أكثر الخيارات التي يعتمد عليها الأهالي في وجباتهم اليومية.\",\n",
            "    \"تستقبل الأسواق كميات مناسبة من المزارع.\",\n",
            "    \"تشهد الأسواق حركة معتدلة منذ بداية اليوم.\",\n",
            "    \"تعتمد الكثير من المواطنين على متابعة حركة السوق اليومية.\",\n",
            "    \"أسعار الدواجن تتراوح بين 75 و80 جنيهًا للكيلو.\",\n",
            "    \"البط البلدي: 140 جنيهًا للكيلو.\",\n",
            "    \"الرومي: 140 حتى 160 جنيهًا.\",\n",
            "    \"الهياكل: 35 إلى 40 جنيهًا.\"\n",
            "  ],\n",
            "  \"story_category\": \"economy\",\n",
            "  \"story_entites\": [\n",
            "    {\n",
            "      \"entity_value\": \"أسواق الدواجن بالدقهلية\",\n",
            "      \"entity_type\": \"location\"\n",
            "    },\n",
            "    {\n",
            "      \"entity_value\": \"المواطنون\",\n",
            "      \"entity_type\": \"person-male\"\n",
            "    },\n",
            "    {\n",
            "      \"entity_value\": \"المزارع\",\n",
            "      \"entity_type\": \"organization\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fiaMIS5k6S4-",
      "metadata": {
        "id": "fiaMIS5k6S4-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "q5DlBDKa-cCg",
      "metadata": {
        "id": "q5DlBDKa-cCg"
      },
      "source": [
        "## Cost Estamation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FDqH7Gqz-do3",
      "metadata": {
        "id": "FDqH7Gqz-do3"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "from faker import Faker\n",
        "import random\n",
        "from datetime import datetime\n",
        "\n",
        "start_time = datetime.now()\n",
        "fake = Faker('ar')\n",
        "\n",
        "input_tokens = 0\n",
        "outpot_tokens = 0\n",
        "\n",
        "for i in tqdm(range(20)):\n",
        "  prompt = fake.text(max_nb_chars=random.randint(200, 300))\n",
        "\n",
        "  messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ]\n",
        "  response = generate_responce(messages)\n",
        "\n",
        "  input_tokens += len(tokenizer.apply_chat_template(messages))\n",
        "  outpot_tokens += len(tokenizer.encode(response))\n",
        "\n",
        "\n",
        "total_time = (datetime.now() - start_time).total_seconds()\n",
        "\n",
        "print(f\"Total Time: {total_time} seconds\")\n",
        "print(f\"Input Tokens: {input_tokens}\")\n",
        "print(f\"Output Tokens: {outpot_tokens}\")\n",
        "print(f\"Total Tokens: {input_tokens + outpot_tokens}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GMUCwDpl2AEf",
      "metadata": {
        "id": "GMUCwDpl2AEf"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4_3pBfhd2AJV",
      "metadata": {
        "id": "4_3pBfhd2AJV"
      },
      "source": [
        "## VLLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vSQC1naqyLd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSQC1naqyLd4",
        "outputId": "0a3c6600-0ce5-435d-d070-667e40ea3555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        }
      ],
      "source": [
        "base_model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "ft_model_id = \"/content/drive/MyDrive/fine_tunning_qwenn\"\n",
        "\n",
        "\n",
        "!nohup vllm serve \"{base_model_id}\" --dtype=half --gpu-memory-utilization 0.8 --max_lora_rank 64 --enable-lora --lora-modules news-lora=\"{ft_model_id}\" &\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fBY6qX_K6Gvb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBY6qX_K6Gvb",
        "outputId": "2928a100-0a70-482e-94ba-dd8f609a4edf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.12.12\n"
          ]
        }
      ],
      "source": [
        "!python --version\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hGF7ZRFB7NJ9",
      "metadata": {
        "id": "hGF7ZRFB7NJ9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2bdb239cbe344dc4b5ba2fa007e6382a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dac19164a5684ddbb930ad71d7406364",
            "placeholder": "​",
            "style": "IPY_MODEL_7702072abcc845ce838e56ac26b47a66",
            "value": "Map: 100%"
          }
        },
        "4adcffa7cef14e29b65a0b4d86438fbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7702072abcc845ce838e56ac26b47a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bc22078ea5e469e98115a30e4b32b19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a19a6d5e9ca8489fb90e89055f026f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bc22078ea5e469e98115a30e4b32b19",
            "placeholder": "​",
            "style": "IPY_MODEL_b321558e1b2d4faaab5a1cc96f36e7e6",
            "value": " 2700/2700 [00:50&lt;00:00, 55.47 examples/s]"
          }
        },
        "b217a4b96dc748caba3e6f6ecbcb307f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b321558e1b2d4faaab5a1cc96f36e7e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd98509785e54ca6822aa199aa9aec47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6187457069b495b8d1c8ac3fa366f95",
            "max": 2700,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b217a4b96dc748caba3e6f6ecbcb307f",
            "value": 2700
          }
        },
        "d6187457069b495b8d1c8ac3fa366f95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dac19164a5684ddbb930ad71d7406364": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff1c6147c0be4d19b00709829f44b74c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bdb239cbe344dc4b5ba2fa007e6382a",
              "IPY_MODEL_cd98509785e54ca6822aa199aa9aec47",
              "IPY_MODEL_a19a6d5e9ca8489fb90e89055f026f02"
            ],
            "layout": "IPY_MODEL_4adcffa7cef14e29b65a0b4d86438fbd"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}